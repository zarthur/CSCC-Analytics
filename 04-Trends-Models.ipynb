{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4: Identifying Trends and Creating Models\n",
    "\n",
    "## Contents\n",
    "\n",
    "* [Getting Started](#Getting-Started)\n",
    "* [Linear Models](#Linear-Models)\n",
    "    * [An Example](#An-Example)\n",
    "    * [Simple Linear Regression](#Simple-Linear-Regression)\n",
    "    * [Multiple Linear Regression](#Multiple-Linear-Regression)\n",
    "    * [Linear-Like Regression](#Linear-Like-Regression)\n",
    "* [Logistic Regression](#Logistic-Regression)\n",
    "    * [An Example](#An-Example)\n",
    "    * [Home Data](#Home-Data)\n",
    "* [Lab Answers](#Lab-Answers)\n",
    "* [Next Steps](#Next-Steps)\n",
    "* [Resources and Further Reading](#Resources-and-Further-Reading)\n",
    "* [Notes](#Notes)\n",
    "* [Exercises](#Exercises)\n",
    "\n",
    "### Lab Questions\n",
    "\n",
    "[1](#Lab-1), [2](#Lab-2), [3](#Lab-3), [4](#Lab-4), [5](#Lab-5), [6](#Lab-6), [7](#Lab-7), [8](#Lab-8)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In previous units, we worked on loading, cleaning, and exploring data.  While working with the data, we noted that certain relationships appeared to exist between columns/variables.  While plots allowed us to make claims like \"x increases as y decreases\",  we didn't try to model that relationship mathematically nor did we try to determine the quality of that model.  \n",
    "\n",
    "In this unit,we'll look at creating models for the relationships in our data; specifically, we'll look at linear models for numerical data and logistic models for categorical data.\n",
    "\n",
    "To create and explore these models, we'll use the [StatsModels](https://www.statsmodels.org/stable/index.html) library. To install it, we'll use `!pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with plots in this unit.  To ensure they are displayed in the notebook itself, we'll need to use the `%matplotlib inline` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the Seaborn and pandas libraries, we'll make explicit use of libraries on which they depend.\n",
    "\n",
    "- [matplotlib.pyplot](https://matplotlib.org/api/pyplot_api.html): a collection of plotting functions with [MATLAB](https://www.mathworks.com/products/matlab.html)-like syntax\n",
    "- [numpy](http://www.numpy.org/): scientific computing library\n",
    "\n",
    "We'll import these and StatsModels with names that follow standard convention.\n",
    "\n",
    "We also set the figure size for plots and a marker size for outliers in box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,8), \"lines.markeredgewidth\": 0.5 })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of model we'll look at are linear models also known as linear regressions. In basic terms,  we use a linear model if the data looks like a line could be drawn through it.  More specifically, for two dimensional data, we try to model the relationship between two variables, the independent or input variable, *X*, and the dependent or response variable, *Y*, by an equation of the form \n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "Y = \\beta_0 + \\beta_1 X\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $\\beta_0$ and $\\beta_1$ are *coefficients*. We can generalize this to more than two dimensions. If $X_1, X_2, \\ldots, X_n$ are independent variables, and $Y$ is the dependent variable, we try to model the relationship by an equation in the form\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $\\beta_0, \\beta_1, \\ldots, \\beta_n$ are the coefficients.\n",
    "\n",
    "To find the coefficients of these equations, we'll rely on the [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) method that attempts to minimizing the the sum of squares of the differences between the observed values and the predicted values - we'll explore this further in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of how we can calculate the coefficients of a linear equation that models some data. We'll start with an example based on the [StatsModels documentation](http://www.statsmodels.org/stable/examples/notebooks/generated/ols.html).\n",
    "\n",
    "First, we generate our \"observed\" data.  To do this, we'll use the Numpy [*linspace()*](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) function to generate 100 evenly-spaced values between 0 and 10; these will correspond to values that will be used for the independent variable.  Next, we'll use the [*normal()*](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html) function from NumPy's [*random*](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html) submodule to draw 100 samples from a normal distribution - this will simulate errors in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsample = 100\n",
    "x = np.linspace(0, 10, nsample)\n",
    "e = np.random.normal(size=nsample)\n",
    "\n",
    "display(x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first 10 values of `x`, we can see that they are stored in an [array](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.array.html).\n",
    "\n",
    "Next, we calculate our \"observed\" values as a combination of the independent variable, a constant, and some error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 5 * x + 3 + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the values of `x` and `y`.  We'll create a scatter plot but use a different approach to do this.  \n",
    "\n",
    "First, we create [figure](https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure) and [axes](https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes) objects using the pyplot [*subplots()*](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots.html) function; this is useful when we want to plot items from different sources together (as we will do in a bit). We use the axes' [*plot()*](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot) method to plot the coordinate pairs from `x` and `y`; the third argument indicates that we'd like to use blue plus-sign markers rather than draw lines from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, 'b+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the plot, the data does look linearly related.  One measure of the strength of the relationship is the [correlation coefficient](https://en.wikipedia.org/wiki/Correlation_coefficient).  Given two variables, the correlation coefficent can have a value between -1 and 1 where -1 indicates strong, negative relationship (as one variable increases, the other decreases) and 1 indicates a strong, postive relationship (as one variable increases, the other increases); a valeu of zero indicates no relationship exists.\n",
    "\n",
    "To calculate the correlation coefficient, we can use the NumPy [*corrcoef()*](https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is the correlation coefficient matrix that shows from left to right, top to bottom, correlation cofficient between the first variable and itself, the correlation cofficient between the first variable and the second, the correlation cofficient between the second variable and the first, and the correlation cofficient between the second variable and itself.  We expect that a variable will be strongly correlated with itself.  The output indicates a strong relationship between the variables.  By construction, the relationship is not only strong, it is also very linear.  To see this, we can use a linear regression.\n",
    "\n",
    "In the two-dimensional linear regression. we need to calculate the values of two coefficients: a constant and a value that will be multiplied by the value of the independent variable.  As we saw above, we can write the linear model in the form\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "Y = \\beta_0 + \\beta_1 X\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We can write the constant, $\\beta_0$ as $\\beta_0 X^0$  Since any value raised to the zeroth power is one, we can write $\\beta_0$ as $1 \\cdot \\beta_0$.  We can say that the dependent variable is a linear combination of 1 and the independent variable.  For our model, we account for this by using the StatsModels' [*add_constant()*](http://www.statsmodels.org/dev/generated/statsmodels.tools.tools.add_constant.html) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(x)\n",
    "display(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing `X` to `x` we now have an array of arrays where the first element in the inner arrays are `1` corresponding to the value of the independent variable for the constant term. \n",
    "\n",
    "To compute the the linear regression, we first set up the ordinary least squares model using the StatsModels' [*OLS*](http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) function and by specifying the array of values for the dependent variable and the array of values for the independent variable.  \n",
    "\n",
    "With the model created, we calculate the regression coefficients using the model's [*fit()*](http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit.html#statsmodels.regression.linear_model.OLS.fit) method; this method returns a [*RegressionResults*](http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.html) object. To dispaly information about the fit, we display the output of the result's [*summary()*](http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.summary.html#statsmodels.regression.linear_model.RegressionResults.summary) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "display(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the coefficients, their p-values, and the value of `R-squared` are particularly of interest.  We can access these directly from `results` using the *params*, *pvalues*, and *rsquared* properties as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters: ', results.params)\n",
    "print(\"P-values:\", results.pvalues)\n",
    "print('R^2: ', results.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients appear in the same order in which the independent variables appear in `X`.\n",
    "\n",
    "Note that this is \"close\" to the equation we used to generate the data - the discrepancy is due to the error we introduced.  \n",
    "\n",
    "Let's plot the regression line along with our data.  We can repeat the same steps as before to create the scatter plot.  We make an additional call to *plot()* and specify the y-values as the output from the results *predict()* method which returns the predicted values of the dependent variable based on the regression results.  Specifying `'r'` for the third argument to plot indicates that we would like the line to be red.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax.plot(x, y, 'b+')\n",
    "ax.plot(x, results.predict(), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [p-value](https://en.wikipedia.org/wiki/P-value) associated with each coefficient indicates how likely changes to the corresponding independent variable account for changes in the dependent variable.  A p-value close to zero (typically, less than 0.05) indicates that the independent variable provides a meaningful addition to the model. <sup><a href=\"#note-1\">1</a></sup>\n",
    "\n",
    "The `R-squared` value is also known as the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) and provides a measure of how well the regression line fits the data.  The coefficient of determination can range from 0 to 1 with 0 indicating (in some regressions, the value can be negative) and indicates how much of the variation in dependent variable can be explained by the model - a value of 1 indicates that all variation is explained by the model and 0 indicates that the model accounts for none of the variation. In this example, some of the variation is due to the error we introduced - changing the magnitude of the error or the parameters of the distribution from which values were drawn will result in a better or worse coefficient of determination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example based on real data.  To begin, we'll load the fuel economy data we processed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_data = pd.read_csv(\"./data/02-vehicles.csv\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a description of the data is available in `./data/02-vehicles-description.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(filename=\"./data/02-vehicles-description.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this unit, we'll work the the following columns.\n",
    "\n",
    "- `co2`\n",
    "- `comb08`\n",
    "- `cylinders`\n",
    "- `displ`\n",
    "- `highway08`\n",
    "- `city08`\n",
    "\n",
    "We can also remove rows with missing or non-positive values.  Because the DataFrame consists of only numeric data, we can use a sort of shortcut for removing rows with non-positive values.  We create a mask applied to the entire DataFrame rather than a specific column - this applies it to all columns.  We then use *all()* with an argument of 1 to indicate that the property applies across all columns.  Effectively this mask will match any row in which all the values are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset = epa_data[['co2', 'comb08', 'cylinders', 'displ', 'highway08', 'city08']].copy()\n",
    "epa_subset = epa_subset[(epa_subset > 0).all(1)].copy()\n",
    "epa_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's look at a the `co2`, `comb08`, `cylinders`, and `displ` columns in `epa_subset`. First we can calculate the correleation coefficient matrix.  With a DataFrame, we can use the *corr()* method to calculate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset[['co2', 'comb08', 'cylinders', 'displ']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get sense of these relationships, visually, we can use a pair plot.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-1\"></a><mark> **Lab 1** In the cell below, create a pair plot for the `co2`, `comb08`, `cylinders`, and `displ` columns in `epa_subset`.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Let's look more closely at the relationship between `Cylinders` and `Displacement`.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-2\"></a><mark> **Lab 2** In the cell below, create scatter plot for the `cylinders` and `displacement` columns in `epa_subset`.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Next, lets create the least squares model and fit a line to the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(epa_subset.cylinders)\n",
    "Y = epa_subset.displ\n",
    "model = sm.OLS(Y, X)\n",
    "res = model.fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `R-squared` value we can see there is a somewhat strong linear relationship between the data; further, the p-value for the coefficient of `cylinders` indicates that changes in `dislp` are likely attributed to changes in `cylinders`.  \n",
    "\n",
    "To plot the fit line with the scatter plot generated by the DataFrame's *plot()* method we can use StatsModel's [*abline_plot()*](http://www.statsmodels.org/dev/generated/statsmodels.graphics.regressionplots.abline_plot.html) function.  First, we import the function then create a scatter plot and store the returned *axes* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import abline_plot\n",
    "axes = epa_subset.plot.scatter(x=\"cylinders\", y=\"displ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can can add the plot of the regression line to the plot using *abline_plot()* function, specifying the model results, the *axes*, and a color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abline_plot(model_results=res, ax=axes, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when creating models, we want to exclude outliers in our calculations.  Let's look at the box plots for `cylinders` and `displ`.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-3\"></a><mark> **Lab 3** In the cells below, create the box plots for `cylinders` and `displ`.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We can see that there are a few outliers for each column.  We can remove them and recalculate the fit.  We can create a copy of the DataFrame from which will will remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_no_outliers = epa_subset[['cylinders', 'displ']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the outliers from a column, we'll create a function that we can apply to a DataFrame.  We'll define outliers based on the interquartile range. \n",
    "\n",
    "After defining the function, we can use it with our `epa_no_outliers` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dataframe, column):\n",
    "    q1 = dataframe[column].quantile(0.25)\n",
    "    q3 = dataframe[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return dataframe[(dataframe[column] >= lower) &\n",
    "                     (dataframe[column] <= upper)].copy()\n",
    "\n",
    "epa_no_outliers = remove_outliers(epa_no_outliers, \"cylinders\")\n",
    "epa_no_outliers = remove_outliers(epa_no_outliers, \"displ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the outliers removed, we can create a new model and calculate the regression coefficients. \n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-4\"></a><mark> **Lab 4** In the cell below, create an ordinary least squares model where `cylinders` is the independent variable and `displ` is the dependent variable. Include a coefficient term in the model. Calculate the fit and store the result in a variable named `res_no_outliers`.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Looking at the result's summary and the `R-squared` value, we can see the the fit is slightly better with the outliers removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(res_no_outliers.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot both the original fit and the fit calculated without outliers against a scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = epa_subset.plot.scatter(x=\"cylinders\", y=\"displ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abline_plot(model_results=res, ax=axes, color='r')\n",
    "abline_plot(model_results=res_no_outliers, ax=axes, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original regression line is colored red and the regression line calculated with outliers removed is colored blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've looked at regressions in which there is one independent variable and a constant.  Often, changes in the response variable are dependent on multiple variables.  For example. we expect that the combined fuel economy is dependent on both city and highway economy. We can see from the scatter plots that `comb08` looks linearly dependent on `city08` and `highway08`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.plot.scatter(x='city08', y='comb08')\n",
    "epa_subset.plot.scatter(x='highway08', y='comb08')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also fit models for each of these individually - `city08`/`comb08` and `highway08`/`comb08`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(epa_subset.city08)\n",
    "Y = epa_subset.comb08\n",
    "model = sm.OLS(Y, X)\n",
    "res = model.fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(epa_subset.highway08)\n",
    "Y = epa_subset.comb08\n",
    "model = sm.OLS(Y, X)\n",
    "res = model.fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separately, the models fit the data quite well.  Let's look at the model in which both `city08` and `highway08` are independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(epa_subset[['city08', 'highway08']])\n",
    "Y = epa_subset.comb08\n",
    "model = sm.OLS(Y, X)\n",
    "res = model.fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the coefficient of determination, we can see this model, which depends on both `city08` and `highway08`, fits the data better than a model which depends on only one of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-Like Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are many of relationships that are linear and that can be modeled using a linear regression, there are also relationships that are non-linear.  Among these non-linear relationships are those that can transformed into a linear ones in terms of the coefficients and independent variables.\n",
    "\n",
    "As an example, consider the relationship between `comb08` and `c02`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.plot.scatter(x=\"comb08\", y=\"co2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this relationship doesn't appear to be linear, it does look [hyperbolic](https://en.wikipedia.org/wiki/Hyperbola). In this case, the relationship between the independent variable and dependent variable could be written as \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "Y = \\frac{1}{\\beta_0 + \\beta_1 X}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "To move the coefficients and independent variable out of the denominator, we can take the reciprocal of both sides (provided the neither side is zero) - this gives us\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "\\frac{1}{Y} = \\beta_0 + \\beta_1 X\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "For a given observation, this form is easier to work with since $\\frac{1}{Y}$ and $X$ are constants and we need to solve for $\\beta_0$ and $\\beta_1$. \n",
    "\n",
    "We can calculate the reciprocal of the dependent variable, `co2`, and store the value in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_non_linear = epa_subset[['comb08', 'co2']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the problem into a linear one, we need to calculate the reciprocal of the `co2` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_non_linear[\"reciprocal_co2\"] = 1/epa_non_linear.co2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot of `comb08` and `reciprocal_c02`, it appears that the relationship is linear, which supports our assumption that the original relationship was hyperbolic.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-5\"></a><mark> **Lab 5** In the cell below, create a scatter plot of `comb08` and `reciprocal_c02`.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "Before fitting the data with a linear model, let's remove the outliers.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-6\"></a><mark> **Lab 6** In the cell below, remove the outliers from the `comb08` and `reciprocal_co2` columns in the `epa_non_linear` DataFrame. Use the *remove_outliers()* function we created earlier.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "With the outliers removed, let's look at the scatter plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = epa_non_linear.plot.scatter(x=\"comb08\", y=\"reciprocal_co2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a linear model for `comb08` and `reciprocal_c02`.  After calculating the coefficients, we display the summary of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(epa_non_linear[\"comb08\"])\n",
    "Y = epa_non_linear[\"reciprocal_co2\"]\n",
    "model = sm.OLS(Y, X)\n",
    "res = model.fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the coefficient of determination, we see that the model produced a good fit. Adding the regression line to the existing scatter plot give the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abline_plot(model_results=res, ax=axes, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to transform the regression line to fit the original data.  Using the *params* property of the results we have the following constant term and coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that our model is \n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "Y = \\frac{1}{0.000068 + 0.000109 X}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We can calculate the predicted values from our model using the following code.  We use *sort_values()* to ensure that the values of the independent variable are in order. This will be important when we plot the curve; we didn't need to do this previously as we relied on the *abline_plot()* function, which handled this for us,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = 1/(res.params.const + \n",
    "                res.params.comb08 * epa_subset.comb08.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the model curve against our original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12,10))\n",
    "axes.plot(epa_subset.comb08, epa_subset.co2, 'b+')\n",
    "axes.plot(epa_subset.comb08.sort_values(), prediction, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) is used to model data where the dependent variable is categorical. In the simplest case, the dependent variable is binary and has only two possible values.  A logistic model, provides an estimate of the probability that one of the two categories applies given the values of the independent variables.  We'll only look at simple case where the dependent variable is binary and there is only one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the the following [example taken from the Wikipedia page on logistic regressions](https://en.wikipedia.org/wiki/Logistic_regression#Example:_Probability_of_passing_an_exam_versus_hours_of_study).  We have two variables: *hours* and *passed*.  The *hours* variable represents the number of hours a student spent studying for an exam and *passed* indicates whether or not the student passed the exam where `0` indicates failure and `1` indicates that the student passed; *hours* is a continuous variable and *passed* is a discrete, binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [0.5, 0.75, 1.0, 1.25, 1.50, 1.75, 1.75, 2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 4.0, 4.25, 4.5, 4.75, 5.0, 5.5]\n",
    "passed = [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting this data as a scatter plot give the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hours, passed, 'b+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression calculates values for $\\beta_0$ and $\\beta_1$ in the following formula\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "P = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $P$ is is a probability value between 0 and 1 and $X$ is the independent variable.\n",
    "\n",
    "We can use the StatsModels [*Logit()*](http://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Logit.html) function to perform the logistic regression.  \n",
    "\n",
    "We have to reassign the value of `stats.chisqprob` due to a discrepancy between the StatsModels module and the libraries on which it depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n",
    "X = sm.add_constant(hours)\n",
    "logit_model=sm.Logit(passed,X)\n",
    "result=logit_model.fit()\n",
    "display(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the model in much the same way as we did for a linear model.  We specify the independent variable and add a constant using StatsModels' *add_constant()* function.  We next create a logistic model using the *Logit()* function.  To calculate the coefficients, we use model's *fit()* method.  After the calculation is complete, we can view a summary of the results.\n",
    "\n",
    "Just like the linear model, the results of the logistic model have a *predict()* method that give the model's predicted values based on the values of the independent variable.  We can use this to plot the logistic curve along with the scatter plot of the data. \n",
    "\n",
    "The model represents the probability of passing the exam given some number of hours spent studying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,8))\n",
    "axes.plot(hours,passed, 'b+')\n",
    "axes.plot(hours, result.predict(), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example with real data, consider the count auditor data we worked with previously.  We can load the data from our local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///data/output.sqlite')\n",
    "home_data = pd.read_sql(\"home_data\", con=engine)\n",
    "home_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, lets see if we can calculate the logistic model that gives the probability of a house having a fireplace given its area.  Currently, the dataset includes the the number of fireplaces a given property has; we need to convert values greater than zero to 1, indicating that there is a fireplace.  \n",
    "\n",
    "First, we drop any rows with missing data. Next, we create a new column, `HasFireplace` that is equal to the mask corresponding the `Fireplaces` being greater than zero. Masks return values of `True` or `False` and the *astype(int)* function call will convert the boolean value to an integer where `False` becomes 0 and `True` becomes 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data.dropna(inplace=True)\n",
    "home_data['HasFireplace'] = (home_data.Fireplaces > 0).astype(int)\n",
    "home_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the scatter plot of `Area` and `HasFireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data.plot.scatter(x=\"Area\", y=\"HasFireplace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the model, we sort the values of our independent variable; this will aid in plotting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data.sort_values(by=[\"Area\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the logistic model and calculating the regression coefficients is similar to the logistic model as we noted in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(home_data.Area)\n",
    "logit_model=sm.Logit(home_data.HasFireplace,X)\n",
    "result=logit_model.fit()\n",
    "display(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model created and the coefficients calculated, we can now plot the regression curve against the original data.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-7\"></a><mark> **Lab 7** In the cell below, create a scatter plot of the `Area` and `HasFireplace` columns from the `home_data` DataFrame.  On the same figure, plot the logistic regression curve.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "The formula for the curve is given by\n",
    "\n",
    "$$\n",
    "\\begin{array}{c}\n",
    "P = \\frac{1}{1 + e^{-(-1.7215 + 0.0008 X)}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "For a given area, we can calculate the probability that the house has a fireplace using this formula based on the model.\n",
    "\n",
    "Let's look at one more example.  Older home tend to have fewer bathroms.  We can create a new column, `MoreThanOneBathroom`\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-8\"></a><mark> **Lab 8** In the cell below, create a new column named `MoreThanOneBathroom` in the `home_data` DataFrame that has a value of 0 if the value of `Bathrooms` is less than or equal to 1 and has a value of 1 otherwise.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We should sort the data by `YearBuilt` before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_data.sort_values(by=[\"YearBuilt\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we construct the model with `YearBuilt` as the independent variable and `MoreThanOneBathroom` as the dependent variable.  We calculate a logistic curve that best fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(home_data.YearBuilt)\n",
    "logit_model=sm.Logit(home_data.MoreThanOneBathroom, X)\n",
    "result=logit_model.fit()\n",
    "display(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create a scatter plot of `YearBuilt` and `MoreThanOneBathroom` along with the logistic regression curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,8))\n",
    "axes.plot(home_data.YearBuilt, home_data.MoreThanOneBathroom, 'b+')\n",
    "axes.plot(home_data.YearBuilt, result.predict(), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Answers\n",
    "\n",
    "1. ```python\n",
    "   sns.pairplot(data=epa_subset[['co2', 'comb08', 'cylinders', 'displ']])\n",
    "   ```\n",
    "   \n",
    "2. ```python\n",
    "   epa_subset.plot.scatter(x='cylinders', y='displ')\n",
    "   ```\n",
    "   \n",
    "3. ```python\n",
    "   epa_subset.cylinders.plot(kind='box')\n",
    "   ```\n",
    "   and\n",
    "   ```python\n",
    "   epa_subset.displ.plot(kind='box')\n",
    "   ```\n",
    "   \n",
    "4. ```python\n",
    "   X = sm.add_constant(epa_no_outliers.cylinders)\n",
    "   Y = epa_no_outliers.displ\n",
    "   model = sm.OLS(Y, X)\n",
    "   res_no_outliers = model.fit()\n",
    "   ```\n",
    "   \n",
    "5. ```python\n",
    "   epa_non_linear.plot.scatter(x=\"comb08\", y=\"reciprocal_co2\")\n",
    "   ```\n",
    "   \n",
    "6. ```python\n",
    "   epa_non_linear = remove_outliers(epa_non_linear, \"comb08\")\n",
    "   epa_non_linear = remove_outliers(epa_non_linear, \"reciprocal_co2\")\n",
    "   ```\n",
    "   \n",
    "7. ```python\n",
    "   fig, axes = plt.subplots(figsize=(10,8))\n",
    "   axes.plot(home_data.Area, home_data.HasFireplace, 'b+')\n",
    "   axes.plot(home_data.Area, result.predict(), 'r-')\n",
    "   ```\n",
    "\n",
    "8. ```python\n",
    "   home_data[\"MoreThanOneBathroom\"] = (home_data.Bathrooms > 1).astype(int)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models we create can be used populate dashboards or included in reports. Later, we'll look at creating visualizations and reporting information. Model creation could also be an intermediate step in the analysis process; in a later unit we'll look at automating model creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Simple and Multiple Linear Regression in Python](https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9)\n",
    "- [Logistic Regression in Python Using Rodeo](http://blog.yhat.com/posts/logistic-regression-python-rodeo.html)\n",
    "- [Regression Analysis with Python by Massaron and Boschetti (Safari Books)](http://proquest.safaribooksonline.com.cscc.ohionet.org/book/programming/python/9781785286315)\n",
    "- [Data Science Algorithms in a Week by Natingga, Regression (Safari Books)](http://proquest.safaribooksonline.com.cscc.ohionet.org/book/programming/machine-learning/9781787284586/regression/1500cb6b_9703_4b4a_bffb_61da8fbd2e97_xhtml?uicode=ohlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a name=\"note-1\"></a> The null hypothesis being tested is that the variable associated with the coefficient has no effect on the dependent variable.  When the p-value is sufficiently low, typically less the 0.05, we reject the null hypothesis thereby accepting that the variable does have an effect on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the coefficients for a linear model relating two columns from the fuel economy or county auditor data not discussed in the examples. Create a scatter plot of the data along with a plot of the regression line.\n",
    "2. Calculate the coefficients for a logistic model relating two columns from the fuel economy or county auditor data not discussed in the examples. Create a scatter plot of the data along with a plot of the regression curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
