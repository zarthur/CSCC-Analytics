{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 1: Requirements and Data Identification\n",
    "\n",
    "## Contents\n",
    "\n",
    "* [Getting Started](#Getting-Started)\n",
    "* [Requirements](#Requirements)\n",
    "    * [Determine Business Objectives](#Determine-Business-Objectives)\n",
    "    * [Assess the Situation](#Assess-the-Situation)\n",
    "    * [Determine Goals](#Determine-Goals)\n",
    "    * [Create a Plan](#Create-a-Plan)\n",
    "* [Data Identification](#Data-Identification)\n",
    "    * [Introduction to pandas](#Introduction-to-pandas)\n",
    "    * [Access Data](#Access-Data)\n",
    "        * [Loading Data from Files](#Loading-Data-from-Files)\n",
    "        * [Loading Data from a Database](#Loading-Data-from-a-Database)\n",
    "        * [Loading Data from an API](#Loading-Data-from-an-API)\n",
    "        * [Scraping Data](#Scraping-Data)\n",
    "    * [Describe Data](#Describe-Data)\n",
    "* [Lab Answers](#Lab-Answers)\n",
    "* [Next Steps](#Next-Steps)\n",
    "* [Resources](#Resources)\n",
    "* [Exercises](#Exercises)\n",
    "\n",
    "### Lab Questions\n",
    "\n",
    "[1](#Lab-1), [2](#Lab-2), [3](#Lab-3), [4](#Lab-4), [5](#Lab-5), [6](#Lab-6), [7](#Lab-7), [8](#Lab-8), [9](#Lab-9),  [10](#Lab-10)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "This notebook makes use of several third-party libraries including [pandas](https://pandas.pydata.org/), [lxml](http://lxml.de/), and [requests](http://docs.python-requests.org/en/master/). Additionally, pandas makes use of [xlrd](https://pypi.python.org/pypi/xlrd) to load data from Excel files.\n",
    "\n",
    "We can use the the [pip](https://pip.pypa.io/en/stable/) tool to install these libraries. Typically this tool is executed from the command line but we can call it from within the notebook using `!` to execute shell commands. Though it's possible to use `!pip` to execute pip, this can cause problems in some environments. Instead, we get the path to the current python interpreter and run it with the pip module.\n",
    "\n",
    "If using [Anaconda](https://www.anaconda.com/download) and the following fails, try \n",
    "\n",
    "```python\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas lxml requests xlrd\n",
    "```\n",
    "\n",
    "To execute a cell, click in it and press `SHIFT` and `ENTER` on the keyboard, click the \"run cell\" button, or select \"Run\" and \"Run Cells\" from the menus above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas lxml requests xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Cross-industry standard process for data mining](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining), or CRISP-DM, is a model for the data mining process.  With data mining and data analytics being very interrelated, much of the CRISP-DM model can be applied to analytics.  CRISP-DM breaks the data mining process into phases with the first phase focusing on business understanding and proper planning based on that understanding.  We can separate the business understanding phase into four parts: determining business objectives, assessing the situation, determining goals, and creating a plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Business Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, it is important to understand, as throughly as possible, what the customer wants to accomplish.  While there is often a primary goal the customer would like to achieve, there are often related goals that could be addressed. Identifying related goals early in the process could save time later.  \n",
    "\n",
    "When determining objectives, it is also important to note what constrains exists such as limitations on access to data or potential data quality issues.\n",
    "\n",
    "For example, marketing might want to examine previous efforts and results in an attempt to determine which strategies were effective or characterize the most likely customers.  In this case, past marketing campaign data and data about potential customers would need to be available.\n",
    "\n",
    "If the goal were to minimize distribution costs, it would be important to be aware of the factors that influence those costs.  If the company relies on a third party for product transportation, we would likely need to collect competitor pricing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quickly establish the customer's objectives in the previous step, only a rough idea available resources and constraining factors was necessary.  Before analytics goals can be formulated and a plan created, it is important to develop a more detailed understanding of the availability of resources, the existence of constraints, and any assumptions that must be made. \n",
    "\n",
    "When considering resources it is important to not only list those that are available but also when they will be available.  Naturally, relevant data is a critical resource and it will be important to note any access restrictions that might exist. It is also important to consider personnel, hardware, and software when assessing resource availability.  \n",
    "\n",
    "If it is determined that there is a lack of resources, whether a shortage of personnel or insufficient data, a plan should be developed to resolve this.  Can required data be collected? If so, how long will it take before the needed data is available?\n",
    "\n",
    "Knowing constraints and assumptions as early in the process as possible, allows the analytics team to address and prepare for them rather than spend time reacting later.  In addition to resource constraints due to time or cost, it's important to determine any legal or security-related constraints. Once limitations and constraints are known, a list of risks that could delay the project can be compiled.  Methods to mitigate risk and contingency plans should also be developed.\n",
    "\n",
    "As part of this cataloging process, a glossary of terminology should also be created.  This glossary should include both business- and analytics-specific terminology.  Such a glossary can facilitate communication and ensure that both the customer and analytics team understand each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the customer's existing goals drove the discussion and process in the previous steps, it's important to developed related, analytics-specific goals.  Just as the business goals will use business terminology, the analytics goals should make use of analytics terminology.  It's import that these goals be as specific and well-defined as possible.  With each goal, success criteria and identification of who is responsible for evaluating success should be established."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once goals and success criteria are established, the steps necessary to achieve the goals should be developed.  For each stage of the analytics process, inputs, resources, outputs, and duration should be determined; specific tools and techniques should also be identified. As part of the planning process, dependencies and scheduling issues should be analyzed to minimize risk.  \n",
    "\n",
    "The project plan is dynamic. At the end of each stage, a review of the remaining phases of the plan should be conducted and updates made accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a plan has been developed and data is made available, it is important to develop an initial understanding of the data, identifying what it contains, and determining whether what is available is sufficient to complete the analytics objectives or not. \n",
    "\n",
    "To access and interrogate data, we'll make use of functionality included in the standard library, the set of tools included with python, as well as third-party libraries. One such library is [pandas](https://pandas.pydata.org/), which can be used to load data in a variety of formats from a variety of sources. The pandas library includes data structures and tools developed to aid in data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading data with pandas, let's explore two of the common data structures pandas provides: the [Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html) and the [DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html).  A Series is used to store one-dimensional data while a DataFrame can be used for two-dimensional, or tabular, data. \n",
    "\n",
    "To begin, we import the pandas module and follow convention of naming it *pd*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pandas imported, we can create a Series.  While there are a variety of ways to do this, we'll use a list here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view to the contents of the Series, we can use the *print()* or *display()* functions. When using a notebook, we can also display its contents by referencing the Series on the last line of a cell. Here we see that in addition to the values in the original list, an index associated with each element is also displayed.  The data type of the elements is displayed as we well.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-1\"></a><mark> **Lab 1** In the cell below, use the *display()* or *print()* to display the contents of the DataFrame stored in the `data` variable.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "To access the values stored in the Series themselves, we can use the *values* attribute.  Here, the values are stored using a [NumPy](http://www.numpy.org/) array.  NumPy is a scientific computing package and it useful for working with numerical or high-volume data; pandas relies heavily on NumPy. NumPy arrays have methods that allow us to transform an array to a traditional Python data structure such as a list; a pandas Series exposes this functionality as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a Series values\n",
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert the array of values to a list\n",
    "data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Series to a list using the underlying array's tolist() method\n",
    "data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we didn't have to use the *print()* or *display()* functions to display content. If the last statement of a cell is an object by itself or an operation that doesn't assign the value to a variable, Jupyter notebook will display the string representation of that object or result as though the *display()* function were used.  For example, because `data.values` was the last statement of the cell, the content of `data.values` was displayed.\n",
    "\n",
    "As noted earlier, values in a Series are also associated with an index.  We can manually specify an index or allow pandas to generate one as was done for our series.  To access the index, we can use the Series *index* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series \n",
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatically-generated index is represented by the *RangeIndex* class that describes the index. This is a more memory-efficient way of storing the index data than creating an array containing each value.  If necessary, we can generate the corresponding array using the *values* attribute.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-2\"></a><mark> **Lab 2** In the cell below, use the *values* attribute of `data.index` to display the underlying array.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "To access elements within a series, we can use the same bracket notation used with other data structures in Python such lists.  For example, to access the second element, we can execute `data[1]`.  As with most other data structures in Python, Series are zero-indexed and begin numbering at zero.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the second element\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List lists, Series also support slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice of elements starting at index 1 and up to but not including index 4.\n",
    "data[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a Series, we can specify the index using the *index* keyword argument.  As shown in the example below, an index does not need to be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series with index specified\n",
    "data = pd.Series([60, 65, 68, 63, 61], index=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with a non-numeric index, we can still access elements in a series using bracket or slice notation.  Note that slices include the last element in the slice when working with non-numeric indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access an element using an index label\n",
    "data[\"Mon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"Lab-3\"></a><mark> **Lab 3** In the cell below, use the bracket notation and slicing to access values with index labels between `Mon` and `Thu`.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "The pandas library supports working with data from a variety of sources and data structures.  In previous examples, we created Series objects using lists.  Below is an example in which a Series is created from dictionary. Note that prior to Python 3.7, the order of dictionary keys is not guaranteed; this affects the order in which values appear in the Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of temperatures\n",
    "temperatures = {\"Mon\": 60, \"Tue\": 65, \"Wed\": 68, \"Thu\": 63, \"Fri\": 61}\n",
    "temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series from a dictionary\n",
    "data = pd.Series(temperatures)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing\n",
    "data[\"Mon\":\"Thu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas library provides the DataFrame data structure for use with two dimensional data.  One can think of the DataFrame as an extension of a Series in the sense that a DataFrame consists of multiple Series.  For example, suppose we have two Series representing high and low daily temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two Series\n",
    "low_temps = pd.Series({\"Mon\": 52, \"Tue\": 49, \"Wed\": 55, \"Thu\": 53, \"Fri\": 51})\n",
    "high_temps = pd.Series({\"Mon\": 60, \"Tue\": 65, \"Wed\": 68, \"Thu\": 63, \"Fri\": 61})\n",
    "display(low_temps, high_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a DataFrame, we can specify a dictionary where keys represent column names and the corresponding values are the Series containing data.  Below, the `forecast` DataFrame is created with the two Series created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from two series\n",
    "forecast = pd.DataFrame({\"high\": high_temps, \"low\": low_temps})\n",
    "forecast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that pandas automatically aligns Series' data based on index value.  The combined indexes of the Series serve as the index for the DataFrame.  We can specify the order of the index when we create the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify index\n",
    "forecast = pd.DataFrame({\"high\": high_temps, \"low\": low_temps}, index=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"])\n",
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we could with Series, we can access the index of a DataFrame using the *index* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display index\n",
    "forecast.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame's index serves to identify values in one dimension.  For one-dimensional Series objects, a value for the index is sufficient to identify a specific value. Because DataFrames represent two-dimension data, an index is not enough to identify a specific value. In a DataFrame, column labels are used to identify the second dimension.  To view a DataFrame's columns, we can use the *column* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display columns\n",
    "forecast.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access values associated with a column, we can use bracket notation with the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a column using bracket notation\n",
    "forecast['high']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame also has attributes corresponding to its columns allowing us to access column data using the dot operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing a column using an attribute\n",
    "forecast.high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each DataFrame column is a Series, we can verify this using the *type()* or *isinstance()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns are Series\n",
    "type(forecast.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns are Series\n",
    "isinstance(forecast.high, pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with Series, we can access data stored in a DataFrame using the *values* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underlying values\n",
    "forecast.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the DataFrame represents two-dimensional data, its values are stored as a NumPy array of nested NumPy arrays where each inner array corresponds to a row. Like most objects that represent a collection, arrays support bracket notation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row\n",
    "forecast.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row, second value\n",
    "forecast.values[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this method of accessing data based on the DataFrames underlying array works, it is cumbersome. We can instead use the DataFrame's index and columns.  As we saw earlier, we can use a column's name to access its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access column by name\n",
    "forecast['low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a row, we rely on the index corresponding to the row and the DataFrame's *loc* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a row by index label\n",
    "forecast.loc['Wed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `forecast` DataFrame has string index values but we can still use integers to specify a specific row through the use of the *iloc* attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a row by position\n",
    "forecast.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine these methods of accessing specific rows and columns to access a specific value within the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.loc['Wed']['low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast['low'].loc['Wed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can specify both the index and column name simultaneously when using *iloc* or *loc*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.loc['Wed', 'low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using column names and index values/labels to access data gives more context to what the corresponding data represents than using the DataFrame's underlying array.\n",
    "\n",
    "We can also use slicing with a DataFrame's index or columns. To specify a column slice, we must use the *loc* or *iloc* properties.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-4\"></a><mark> **Lab 4** In the cell below, slicing with the DataFrame's *loc* attribute to display rows where the index is between `Mon` and `Wed`.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We can use slicing with columns and rows simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row and column slicing\n",
    "forecast.loc['Mon':'Wed', 'high':'low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use bracket notation to apply a mask to a DataFrame.  For example, if we want to view rows in which the high temperature is 65 or greater we can create the following mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask\n",
    "mask = forecast.high >= 65\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the mask to the DataFrame effectively filters the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a mask\n",
    "forecast[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage to using DataFrames is the ease with which we can manipulate the data.  For example, the following line calculates the mean temperature value for each row and stores the value in a new column.  Had we used another data structure, we might have had to write a for-loop to do this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate new column's values\n",
    "forecast['mean'] = (forecast['high'] + forecast['low']) / 2\n",
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, for performance reasons, we should try to avoid the use of for-loops when manipulating data stored in a DataFrame.  A for loop will certainly work if needed though.  We can iterate through a DataFrame's rows using the *iterrows()* method which returns the index and row content separately as we move from row to row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display index and row data for each row\n",
    "for index, row in forecast.iterrows():\n",
    "    print(\"Index:\", index)\n",
    "    print(\"Row:\", row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use a loop to manipulate row values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate difference using a for loop\n",
    "forecast['difference'] = 0  # create new column with all zeros\n",
    "for index, row in forecast.iterrows():\n",
    "    row['difference'] = row['high'] - row['low']\n",
    "    forecast.loc[index] = row  # iterrows creates a copy, we need to explicitly update the dataframe\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we continue working with pandas, additional features will explored. For a more in-depth introduction to pandas, see the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing data will depend on how it is stored. If the relevant data is stored as a spreadsheet, one will need access to the spreadsheet file and the necessary tools to read the file.  Similarly, the appropriate tools are required to access data stored in a database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data from Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files tend to be a commonly used container for data, creating the files is relatively easy with spreadsheet software and sharing the data can be as easy as attaching a file to an email.  Accessing data from a file in Python is also relatively easy. The file we'll use for these examples is from [Kaggle](https://www.kaggle.com/), which hosts both datasets and notebooks. Specifically, we'll use an [HR dataset](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset) created by IBM that includes HR data about employees.  \n",
    "\n",
    "We can use Python's standard library, the collection of data structures and tools included with Python, to load the data contained in `data/01-attrition.csv`.  \n",
    "\n",
    "As a first step, let's examine the source CSV.  When working with text data like a CSV, it's helpful to know how fields are separated, using a delimiter, relying on a fixed width for each column, or by some other means.\n",
    "\n",
    "In the code below, we start by opening the source CSV for reading and assigning it to the variable `infile`.  To read only the first five lines of the CSV, we'll use a while-loop that continues as long as the `line_number` variable has a value less than 5. Before entering the loop, we'll initialize the variable with a value of 0.  Each iteration through the loop, we'll read a line from the file, print the line, and increment the `line_number` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/01-attrition.csv\") as infile:\n",
    "    line_number = 0\n",
    "    while line_number < 5:\n",
    "        print(infile.readline())\n",
    "        line_number += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output, it appears that the data is comma-separated as we would expect in a CSV (comma-separated values) file. We can also see that the first line contains header data.\n",
    "\n",
    "The Python standard library includes a [CSV module](https://docs.python.org/3/library/csv.html) for working with CSV data. Among the tools in this module is the [*Sniffer*](https://docs.python.org/3/library/csv.html#csv.Sniffer) class that can be used to determine formating information for a CSV. The code below reads the first ten kilobytes of the file to determine formatting information; the value can be increased as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"./data/01-attrition.csv\") as infile:\n",
    "    dialect = csv.Sniffer().sniff(infile.read(10000))\n",
    "\n",
    "print(f\"Delimter: {dialect.delimiter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is consistent with what we saw from the first five lines of the data.  \n",
    "\n",
    "Typically, we load the contents of a file one line at a time.  To store all the file's lines, we'll create an empty list and store it in the variable named `csv_data`.  Next, we can open the file and specify its [encoding](https://en.wikipedia.org/wiki/Character_encoding) as `UTF-8-sig`, which indicates that the file contains [UTF-8]((https://en.wikipedia.org/wiki/UTF-8) encoded data with an optional [byte order mark](https://en.wikipedia.org/wiki/Byte_order_mark).  The variable used to refer to the file object is named `csv_file`. Using `with` will keep the file open only for as long as we need it and allows us to avoid having to write code to explicitly close the file.  \n",
    "\n",
    "We can use the csv module's *reader()* function to iterate through the file line by line. The *reader()* function takes an optional *dialect* parameter that will allow us to specify dialect information extracted by a *Sniffer* if its available. Each line is represented by a list with elements corresponding to the different field values in the line. As we read through the file, we will append each line to the first list we created, `csv_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from CSV file\n",
    "import csv\n",
    "\n",
    "csv_data = []\n",
    "# open the file for reading\n",
    "with open('./data/01-attrition.csv', encoding='utf-8-sig') as csv_file:\n",
    "    # create a csv reader using the exsiting dialect information\n",
    "    reader = csv.reader(csv_file, dialect=dialect)\n",
    "    # iterate through the csv's rows and append to the csv_data list\n",
    "    for row in reader:\n",
    "        csv_data.append(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate through `csv_data` to display the first few rows of data.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-5\"></a><mark> **Lab 5** In the cell below, use a for-loop to display the first five rows of data in `csv_data`.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Examining the output, we see that the first five elements of the `csv_data` list are themselves lists; each of these lists corresponds to a line from the original file. Each of these lists, in turn, have elements that correspond to individual values. \n",
    "\n",
    "There are a variety of ways we can structure this data for convenient access.  One way is to create a list of dictionaries where each dictionary corresponds to a row of data with field names as dictionary keys and row data as dictionary values. To construct this list of dictionaries, we'll iterate through `csv_data`.  As a first step, lets assign the first row to a new variable named `fields`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = csv_data[0]\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a list to store the dictionaries representing each row; we'll assign this list to the `hr_data` variable.  We next iterate through the remaining rows of `csv_data` and create a dictionary for each row.  Recall that each row is itself stored as a list with elements using the `enumerate()` function.  The `enumerate()` function will return both the index of an element in a list as well as the element.  Having the index will allow us to us to access the corresponding field name from the `fields` list.  In the newly created dictionary, we'll pair the field names and field values.  Once we've finished iterating through the row, we'll store the dictionary in the `hr_data` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = []\n",
    "\n",
    "# iterate through the remaining data rows\n",
    "for row in csv_data[1:]:\n",
    "    row_dictionary = {}\n",
    "    \n",
    "    # iterate through the row elements using \n",
    "    for index, element in enumerate(row):\n",
    "        # get the corresponding field name\n",
    "        field_name = fields[index]\n",
    "        # store the element with its field\n",
    "        row_dictionary[field_name] = element\n",
    "        \n",
    "    #add the dictionary to the list\n",
    "    hr_data.append(row_dictionary)\n",
    "    \n",
    "# diplay the data from the second row of data\n",
    "hr_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure will allow us to easily access data for each record.  For example, we can print the ages of the first ten records using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in hr_data[:10]:\n",
    "    print(record['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is an improvement over the list-of-lists structure we initially created when loading the CSV data, there are still issues with the way we've stored the data. One issue is that all the data is stored as strings.  While this is fine for some fields such as `Business Travel` or `Department`, it would be preferable to store other fields like `Age` as numeric values.  To demonstrate this problem, let's try to calculate the mean age of the first ten records. This code will result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_age = 0\n",
    "\n",
    "# iterate through the first 10 records and add each age to the total \n",
    "for record in hr_data[:10]:\n",
    "    total_age += record['Age']\n",
    "    \n",
    "\n",
    "total_age/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code caused an error because we tried to add an integer, 0, and a string, the value associated with `Age`.  To fix this we would have had to convert the value when we loaded the data or when we tried to do a calculation with it as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_age = 0\n",
    "\n",
    "# iterate through the first 10 records and add each age to the total \n",
    "for record in hr_data[:10]:\n",
    "    # convert age value to an integer then add to total_age\n",
    "    total_age += int(record['Age'])\n",
    "    \n",
    "\n",
    "total_age/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could continue to refine the code we wrote to load the data to include necessary data type conversions.  However, third party libraries exist that try to do this automatically.  One such library is pandas.  With pandas loaded, we can use its `read_csv()` function to load data from a file; we can specify the location of the file as an argument to the function.  The `read_csv` method returns a DataFrame object which we can store in a variable.  To display the first few rows of a DataFrame, we can use the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "hr_data = pd.read_csv('data/01-attrition.csv')\n",
    "\n",
    "# display first 5 rows of data\n",
    "hr_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output is much easier to view and understand than what was displayed when we loaded the contents of the file as a list of lists; this is one of the advantages to using pandas to work with data. This is also do to how pandas integrates with the notebook software, Jupyter. \n",
    "\n",
    "By default, pandas will only display twenty columns.  If there are more than twenty columns, as in this example, pandas will indicate this with ellipses.  To increase the number of columns, we can use the `set_option()` function, specifying the option we want to change as the first argument and its new value as the second. The code below increases the number of displayed columns to fifty then displays the first five rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of displayed columns\n",
    "pd.set_option('display.max_column', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"Lab-6\"></a><mark> **Lab 6** In the cell below, use the DataFrame's *head()* method to display the first five rows of data.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "When loading data, pandas will automatically assign an index to each row. The index appears before the first named column above.  To access a row we can use the `iloc` attribute to access a row by specifying its position in the DataFrame or the `loc` attribute by specifying the label associated with the row in the DataFrame's index; when the index is automatically assigned these two properties can be used interchangeably.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the third row\n",
    "hr_data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the row with index label \"2\"\n",
    "hr_data.loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded into a DataFrame, we can do a variety of things including calculating summary statistics or creating visualizations. For example, we can calculate the mean age of the first ten records using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean age of \n",
    "hr_data.iloc[:10]['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the average age, we didn't have to restructure the data or explicitly change the data type.  This is one of the advantages of using a library like pandas.  \n",
    "\n",
    "To explain the line of code above, let's look at each part.  The `hr_data` variable refers to the DataFrame we created using the CSV data.  We can specify multiple rows by using Python's slice notation with `iloc`.  To specify a particualr column, we can use bracket notation along with the columns name. When we access a subset of the rows, the data structure is still a DataFrame.  When we access a specific column, the data structure used is a related one-dimensional structure known as a [Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html).  Both DataFrames and Series have methods that can be used to manipulate the data stored within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first ten rows, a DataFrame\n",
    "hr_data.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age column of first ten rows, a Series\n",
    "hr_data.iloc[:10]['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the age of the first ten rows\n",
    "hr_data.iloc[:10]['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because slicing is such a common operation, pandas supports specifying slices of rows using bracket notation on a DataFrame directly without having to use the `iloc` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data[:10]['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access columns within a DataFrame  with the dot operator.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-7\"></a><mark> **Lab 7** In the cell below, calculate the mean of the first ten values in the `Age` column.  Use the dot operator rather than bracket notation to access the `Age` column.  The result should be the same as the previous result.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We'll explore more of the features of a DataFrame later but let's continue looking at how we can load data from different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data from a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convenient to store data in a database rather than in individual files.  There are a [variety of Python libraries available](https://wiki.python.org/moin/DatabaseInterfaces) to interact with databases.  One of the most common is [SQLAlchemy](http://docs.sqlalchemy.org/en/latest/dialects/index.html) and pandas includes functionality to work with it.  Before we can use SQLAlchemy, we should make sure it is installed using `pip`.  Typically, we will install the libraries we expect to use before starting work in a notebook but for completeness, this step is included in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we'll use a SQLite database for this example. SQLite databases are convenient because they can be stored as a single file.  The process we'll use to connect to and load data from the SQLite database can be used with other database engines such as Microsoft SQL Server or MySQL.\n",
    "\n",
    "In this example, we'll load data from a commonly used example database, the [Chinook database](https://chinookdatabase.codeplex.com/), which contains data for a fictitious media store.  An diagram of the database structure appears below.\n",
    "\n",
    "<figure>\n",
    "  <img src=\"./images/01-chinook.png\" alt=\"Chinook database diagram\">\t\n",
    "  <figcaption style=\"text-align: center; font-weight: bold\">Diagram of the Chinook Database</figcaption>\n",
    "</figure>\n",
    "\n",
    "In order to load data from a database using pandas, we must first create a connection to the database.  This is done using SQLAlchemy's `create_engine()` function.  Using a resource identifier, we can specify the location to the SQLite database file as an argument when we call the function; see the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/io.html#engine-connection-examples) and [SQLAlchemy documentation](http://docs.sqlalchemy.org/en/latest/core/engines.html) for examples of how to connect to other database engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create a database connection\n",
    "engine = create_engine('sqlite:///data/01-chinook.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use SQLAlchemy alone to load data from the database.  One we've defined an engine, we can use its `connect` method to establish a connection to the database and query the database with the connection.  To demonstrate how we can query the database, we'll query the database for the first five records from the inner join on the `Invoice` and `Customer` tables ordered by `InvoiceID`. First we'll store the query as a string for clarity, then query the database, and finally iterate through the result to display each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database query\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM Invoice INNER JOIN Customer \n",
    "ON Invoice.CustomerId = Customer.CustomerId \n",
    "ORDER BY Invoice.InvoiceID \n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "# open database connection, close when finished\n",
    "with engine.connect() as connection:\n",
    "    # execute query\n",
    "    result = connection.execute(query)\n",
    "    # iterate through results\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each record is represented by a tuple with elements corresponding to field values; this is similar to the structure of the data we initially had when working with the CSV file.  We could write code to make it easier to work with this data or we could rely instead on a library like pandas.  \n",
    "\n",
    "With a connection to the database, we can query the database for data and store the result in a DataFrame using pandas' `read_sql_query()` function.  For this example, we'll load the entire result of the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM Invoice INNER JOIN Customer \n",
    "ON Invoice.CustomerId = Customer.CustomerId \n",
    "ORDER BY Invoice.InvoiceID \n",
    "\"\"\"\n",
    "# query database\n",
    "invoice_customer = pd.read_sql_query(query, engine)\n",
    "\n",
    "# display first five rows\n",
    "invoice_customer.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data from an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many websites that provide access to data often provide a means of accessing that data programmatically using an [application programming interface](https://www.programmableweb.com/api-university/what-are-apis-and-how-do-they-work) or API. A common way to access an API is by making [HTTP](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol) requests of a server in much the same way a web browser would. If the request is valid, the server hosting the API will respond with the requested data.  The response is often [JSON](https://en.wikipedia.org/wiki/JSON) or [XML](https://en.wikipedia.org/wiki/XML) text. \n",
    "\n",
    "To demonstrate this, let's look at the [IEX API](https://iextrading.com/developer/docs/#getting-started), a free API providing stock market data.  To make an HTTP request, we'll use the popular [Requests](http://docs.python-requests.org/en/master/) library.  In addition to providing the ability to make HTTP requests, the Requests library also includes functionality to convert JSON data into Python objects like lists and dictionaries. First, we'll request historic data for a specific stock then display the response as plain text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests module to make HTTP requests\n",
    "import requests\n",
    "\n",
    "# Make an HTTP GET request and store the response\n",
    "response = requests.get(\"https://api.iextrading.com/1.0/stock/aapl/chart\")\n",
    "\n",
    "# display the response content\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the response content or reading the API documentation reveals that the data is JSON formatted.  We can use the `json()` method associated with the response to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process JSON data and convert to python lists and dictionaries\n",
    "stock_data = response.json()\n",
    "\n",
    "# display data\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as a list of dictionaries with each dictionary corresponding to a specific data.  Each dictionary also contains information related to the stock price.  While we could work with the data in this structure, we could also use pandas to make the HTTP request and process the response into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to load API data\n",
    "stock_history = pd.read_json(\"https://api.iextrading.com/1.0/stock/aapl/chart\")\n",
    "\n",
    "# display historic stock data\n",
    "stock_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Scraping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final method of acquiring data that we'll examine is known as [scraping](https://en.wikipedia.org/wiki/Web_scraping). Scraping involves extracting data from a source that is typically meant for human use rather than programmatic manipulation.  Often, data is extracted from a website.  Because many websites explicitly prohibit the use of scraping in their terms of service, we'll use a HTML file created for this example.\n",
    "\n",
    "Before we extract the data, let's see what the page defined by the HTML looks like.  To render HTML within a notebook, we will use the [IPython](https://ipython.org/) `display()` function and `HTML` class.  Jupyter notebooks are closely related to IPython; the Python code written in a Jypter notebook is executed using IPython so we don't need to make sure IPython library is installed before importing parts of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display HTML content\n",
    "from IPython.display import HTML\n",
    "HTML(filename=\"./data/01-table.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the HTML file contains salary data.  Though we've rendered the HTML content, we haven't extracted the data itself.  There are a variety of web scraping libraries available for Python such as [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) but we'll rely on pandas.  The pandas `read_html()` function can be used to extract data stored in HTML tables.  First, let's make sure that the data is, in fact, stored in an HTML table.  To do this, we'll display part of the content of the HTML file as plain text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the html file\n",
    "with open(\"./data/01-table.html\", encoding=\"UTF-8\") as html_file:\n",
    "    # read the entire file\n",
    "    html_data = html_file.readlines()\n",
    "    \n",
    "# display the first 40 lines\n",
    "html_data[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTML includes at least one `table` element so we'll be able to use pandas to extract data.\n",
    "\n",
    "The pandas `read_html()` function will attempt to extract data from each table on a page.  The value returned by `read_html()` is a list of DataFrames with each DataFrame corresponding to a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract table data from HTML\n",
    "html_data = pd.read_html('./data/01-table.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas *read_html()* returns is a list of DataFrames.  Because the HTML document contained only one table, we are interested only in the first element in the returned list.  \n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-8\"></a><mark> **Lab 8** In the cell below, write the code to access the DataFrame corresponding to the first element from this list and display the first five rows of data.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Describe Data\n",
    "\n",
    "Once we've gathered or accessed data from various sources, our next step might be to document the data itself, describing both the the source as well as information about fields including type of data, possible values, and description.\n",
    "\n",
    "When working with a database, we can rely on the structure imposed by the database itself; when tables are created, data types for each field must be specified.  Most database software provides a means of viewing the *Create* statement used to define a table.  For example, all SQLite databases include a `sqlite_master` table that contains information about other tables in the database. Included in this table is a `sql` column that stores the SQL statements used to create the other tables. To retrieve the a table's *Create* statement we can use a query in the following form:\n",
    "\n",
    "`SELECT sql FROM sqlite_master WHERE type='table' AND name='{TABLE_NAME}'`\n",
    "\n",
    "where `{TABLE_NAME}` represents the name of the specific table we're interested in.\n",
    "\n",
    "The following code connects to the database and queries for the *Create* statement for the `Customer` and `Invoice` tables.  The query returns an iterable collection of rows where each element is a dictionary. The dictionary for each row has keys that correspond to field names and values that correspond to field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to be used\n",
    "query_template = \"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'\"\n",
    "\n",
    "# tables names\n",
    "tables = ['Customer', 'Invoice']\n",
    "\n",
    "# connect to the databalse \n",
    "with engine.connect() as connection:\n",
    "    for table in tables:\n",
    "        # substitue table name into query template\n",
    "        query = query_template.format(table_name=table)\n",
    "        # execute the query\n",
    "        result = connection.execute(query)\n",
    "        # iterate through each record\n",
    "        for record in result:\n",
    "            # print the value associated with the 'sql' column\n",
    "            print(record['sql'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this gives us information about the type of data stored in each field - for example, the `Total` field is a number with with ten digits where up to two can be used for decimal values - it doesn't tell us about the range of values.\n",
    "\n",
    "For more insight into the data, we can use pandas.  To see how pandas can be used to document data, let's load a new dataset. This dataset contains sanitized loan data from [Lending Club](https://www.lendingclub.com/info/download-data.action).  \n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-9\"></a><mark> **Lab 9** Use the pandas *read_csv()* function to load loan data from the `./data/01-loan.csv` file and store the DataFrame in a variable named `loan_data`.  Display the first few rows of the DataFrame.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "First, we can get a full list of list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the tolist() method for an easier-to-read listing of column names\n",
    "loan_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every DataFrame has a `describe()` method that provides summary statistics for each column.  By default, `describe()` will only provide information for columns with numeric data. To see this, we start by loading another dataset containing sales data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive stats\n",
    "loan_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have pandas give some descriptive information for the non-numeric fields using the `include` parameter with a value of \"all\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive stats for all columns\n",
    "loan_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the number of unique values, the most frequently appearing value, and that value's frequency.  It's usually helpful to know what the actual unique values ares.  To do this, we'll have to iterate through the columns and work with each column individually as a Series.  Series objects have a `unique` method that will display the Series' unique values.  \n",
    "\n",
    "When iterating through the columns, we'd like to see the unique values for columns with non-numeric data. There are a [variety of ways](https://stackoverflow.com/questions/19900202/how-to-determine-whether-a-column-variable-is-numeric-or-not-in-pandas-numpy) to do this; one way is to use the `is_string_dtype` function in the `pandas.api.types` module. Here, *dtype* means \"data type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through column names, display unique values for string data\n",
    "for column in loan_data.columns:\n",
    "    if pd.api.types.is_string_dtype(loan_data[column]):\n",
    "        display(column, loan_data[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the data types of each column using the `dtypes` attribute of the DataFrame itself.  \n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-10\"></a><mark> **Lab 10** Use the *dtypes* attribute to display the data types for each column of the `loan_data` DataFrame</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "The `object` data type is used for any non-numeric values.  We can convert these values to a more appropriate data type later, if necessary. \n",
    "\n",
    "Having a description of each column would be helpful. For columns where the meaning is unclear, we would consult the data owner for clarification. [Lending Club](https://www.lendingclub.com/info/download-data.action) provides a data dictionary that contains a description for most of the columns that appear in their datasets. The contents of the dictionary are loaded using the `read_excel()` function.  We can specify a column as the index rather than have pandas generate an index automatically by specifying a column number to the `index_col` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data dictionary\n",
    "loan_dicitonary = pd.read_excel(\"./data/01-loan-dict.xlsx\", index_col=0)\n",
    "loan_dicitonary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the dictionary to get descriptions for most of the columns in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print descriptions only for columns being used\n",
    "for column in loan_data.columns:\n",
    "    print(column, \" - \", loan_dicitonary.loc[column][\"Description\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining these pieces of information, we can summarize the loan data fields with a description, the type of data, and description of possible values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th style=\"text-align: left\">Field</th>\n",
    "            <th style=\"text-align: left\">Description</th>\n",
    "            <th style=\"text-align: left\">Data Type</th>\n",
    "            <th style=\"text-align: left\">Possible Values</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">loan_amnt</td>\n",
    "            <td style=\"text-align: left\">The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces\n",
    "                the loan amount, then it will be reflected in this value.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">500 - 35000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">funded_amnt</td>\n",
    "            <td style=\"text-align: left\">The total amount committed to that loan at that point in time.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">500 - 35000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">funded_amnt_inv</td>\n",
    "            <td style=\"text-align: left\">The total amount committed by investors for that loan at that point in time.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 35000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">term</td>\n",
    "            <td style=\"text-align: left\">The number of payments on the loan. Values are in months and can be either 36 or 60.</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">&#39;36 months&#39;, &#39;60 months&#39;,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">int_rate</td>\n",
    "            <td style=\"text-align: left\">Interest Rate on the loan</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>percentage</em>,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">installment</td>\n",
    "            <td style=\"text-align: left\">The monthly payment owed by the borrower if the loan originates.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">15.67 - 1305.16</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">grade</td>\n",
    "            <td style=\"text-align: left\">LC assigned loan grade</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">A - G,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">sub_grade</td>\n",
    "            <td style=\"text-align: left\">LC assigned loan subgrade</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">A1 - A5, ... ,G1 - G5,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">emp_title</td>\n",
    "            <td style=\"text-align: left\">The job title supplied by the Borrower when applying for the loan.*</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>various strings</em>,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">emp_length</td>\n",
    "            <td style=\"text-align: left\">Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means\n",
    "                ten or more years.</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">&#39;&lt; 1 year&#39;, &#39;1 year&#39;, ...&#39;9 years&#39;, &#39;10+ years&#39;,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">home_ownership</td>\n",
    "            <td style=\"text-align: left\">The home ownership status provided by the borrower during registration or obtained from the credit report. Our\n",
    "                values are: RENT, OWN, MORTGAGE, OTHER</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">&#39;RENT&#39;, &#39;OWN&#39;, &#39;MORTGAGE&#39;, &#39;OTHER&#39;, &#39;NONE&#39;,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">annual_inc</td>\n",
    "            <td style=\"text-align: left\">The self-reported annual income provided by the borrower during registration.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">1896 - 6000000</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">verification_status</td>\n",
    "            <td style=\"text-align: left\">Indicates if income was verified by LC, not verified, or if the income source was verified</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">&#39;Verified&#39;, &#39;Source Verified&#39;, &#39;Not Verified&#39;,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">issue_d</td>\n",
    "            <td style=\"text-align: left\">The month which the loan was funded</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>month-year string</em>,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">loan_status</td>\n",
    "            <td style=\"text-align: left\">Current status of the loan</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">&#39;Fully Paid&#39;, &#39;Charged Off&#39;, &#39;Does not meet the credit policy. Status:Fully Paid&#39;, &#39;Does\n",
    "                not meet the credit policy. Status:Charged Off&#39;,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">purpose</td>\n",
    "            <td style=\"text-align: left\">A category provided by the borrower for the loan request.</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">&#39;credit_card&#39;, &#39;car&#39;, &#39;small_business&#39;, &#39;other&#39;, &#39;wedding&#39;, &#39;debt_consolidation&#39;,\n",
    "                &#39;home_improvement&#39;, &#39;major_purchase&#39;, &#39;medical&#39;, &#39;moving&#39;, &#39;vacation&#39;,\n",
    "                &#39;house&#39;, &#39;renewable_energy&#39;, &#39;educational&#39;,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">title</td>\n",
    "            <td style=\"text-align: left\">The loan title provided by the borrower</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>various strings</em>,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">zip_code</td>\n",
    "            <td style=\"text-align: left\">The first 3 numbers of the zip code provided by the borrower in the loan application.</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>sanitized zip codes</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">addr_state</td>\n",
    "            <td style=\"text-align: left\">The state provided by the borrower in the loan application</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>state abbreviation</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">dti</td>\n",
    "            <td style=\"text-align: left\">A ratio calculated using the borrowers total monthly debt payments on the total debt obligations, excluding\n",
    "                mortgage and the requested LC loan, divided by the borrowers self-reported monthly income.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 29.99</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">delinq_2yrs</td>\n",
    "            <td style=\"text-align: left\">The number of 30+ days past-due incidences of delinquency in the borrower&#39;s credit file for the past 2 years</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 13</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">earliest_cr_line</td>\n",
    "            <td style=\"text-align: left\">The month the borrower&#39;s earliest reported credit line was opened</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>month-year string</em>,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">inq_last_6mths</td>\n",
    "            <td style=\"text-align: left\">The number of inquiries in past 6 months (excluding auto and mortgage inquiries)</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 33</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">mths_since_last_delinq</td>\n",
    "            <td style=\"text-align: left\">The number of months since the borrower&#39;s last delinquency.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 120</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">mths_since_last_record</td>\n",
    "            <td style=\"text-align: left\">The number of months since the last public record.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 129</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">open_acc</td>\n",
    "            <td style=\"text-align: left\">The number of open credit lines in the borrower&#39;s credit file.</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">1 - 47</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">pub_rec</td>\n",
    "            <td style=\"text-align: left\">Number of derogatory public records</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">revol_bal</td>\n",
    "            <td style=\"text-align: left\">Total credit revolving balance</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 1207359</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">revol_util</td>\n",
    "            <td style=\"text-align: left\">Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving\n",
    "                credit.</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>percentage</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">total_acc</td>\n",
    "            <td style=\"text-align: left\">The total number of credit lines currently in the borrower&#39;s credit file</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">1 - 90</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">total_pymnt</td>\n",
    "            <td style=\"text-align: left\">Payments received to date for total amount funded</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 58886.47343</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">total_pymnt_inv</td>\n",
    "            <td style=\"text-align: left\">Payments received to date for portion of total amount funded by investors</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 58563.68</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">total_rec_prncp</td>\n",
    "            <td style=\"text-align: left\">Principal received to date</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 35000.02</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">total_rec_int</td>\n",
    "            <td style=\"text-align: left\">Interest received to date</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 23886.47</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">total_rec_late_fee</td>\n",
    "            <td style=\"text-align: left\">Late fees received to date</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 209</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">recoveries</td>\n",
    "            <td style=\"text-align: left\">post charge off gross recovery</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 29623.35</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">collection_recovery_fee</td>\n",
    "            <td style=\"text-align: left\">post charge off collection fee</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 7002.19</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">last_pymnt_d</td>\n",
    "            <td style=\"text-align: left\">Last month payment was received</td>\n",
    "            <td style=\"text-align: left\">object</td>\n",
    "            <td style=\"text-align: left\">\n",
    "                <em>month-year string</em>,\n",
    "                <em>blank</em>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">last_pymnt_amnt</td>\n",
    "            <td style=\"text-align: left\">Last total payment amount received</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 3170.22</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"text-align: left\">pub_rec_bankruptcies</td>\n",
    "            <td style=\"text-align: left\">Number of public record bankruptcies</td>\n",
    "            <td style=\"text-align: left\">float</td>\n",
    "            <td style=\"text-align: left\">0 - 2</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ```python\n",
    "   display(data)\n",
    "   ```\n",
    "   \n",
    "   or\n",
    "   \n",
    "   ```python\n",
    "   print(data)\n",
    "   ```\n",
    "   \n",
    "2. ```python\n",
    "   data.index.values\n",
    "   ```\n",
    "   \n",
    "3. ```python\n",
    "   data[\"Mon\":\"Thu\"]\n",
    "   ```\n",
    "   \n",
    "4. ```python\n",
    "   forecast.loc['Mon':'Wed']\n",
    "   ```\n",
    "  \n",
    "5. ```python\n",
    "   for row in csv_data[:5]:\n",
    "       print(row)\n",
    "   ```\n",
    "   \n",
    "6. ```python\n",
    "   hr_data.head(5)\n",
    "   ```\n",
    "\n",
    "7. ```python\n",
    "   hr_data[:10].Age.mean()\n",
    "   ```\n",
    "   \n",
    "8. ```python\n",
    "   salary_data = html_data[0]\n",
    "   salary_data.head(5)\n",
    "   ```\n",
    "   \n",
    "   or\n",
    "   \n",
    "   ```python\n",
    "   html_data[0].head(5)\n",
    "   ```\n",
    "   \n",
    "9. ```python\n",
    "   loan_data = pd.read_csv(\"./data/01-loan.csv\")\n",
    "   loan_data.head()\n",
    "   ```\n",
    "\n",
    "10. ```python\n",
    "    loan_data.dtypes\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a catalog of the data will help us determine if what we have is sufficient to continue with the project or if we'll need to gather more data.  For example, if we had been asked to determine if factors such as debt-to-income ratio or an internal-assigned grade was reliable in determining whether a loan would be paid off or not, it would appear that we have enough data to proceed based on our initial description of the data.  If, however, we were asked to give different weights to different types of existing debt (credit card balances versus home mortgages, for example), we would have to request additional data.\n",
    "\n",
    "Assuming we have sufficient data, our next step might be to further explore our data characterize it and determine if any relationships exist. Before exploring data, however, the data must be transformed or cleaned to facilitate analysis.  Often, data cleansing and exploration are interwoven tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/)\n",
    "- [*Python Data Analysis* by Fandango, Chapter 5: Retrieving, Processing, and Storing Data (Safari Books)](http://proquest.safaribooksonline.com.cscc.ohionet.org/book/programming/python/9781787127487/python-data-analysis-second-edition/ch05_html)\n",
    "- [*Python Data Science Handbook* by VanderPlas](https://jakevdp.github.io/PythonDataScienceHandbook/)\n",
    "- [*Python for Data Analysis* by Wes McKinney, Chapter 6: Data Loading, Storage, and File Formats (Safari Books)](http://proquest.safaribooksonline.com.cscc.ohionet.org/book/programming/python/9781491957653/data-loading-storage-and-file-formats/io_html)\n",
    "- [Requests Documentation](http://docs.python-requests.org/en/master/)\n",
    "- [SQLAlchemy Documentation](https://www.sqlalchemy.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to compete each exercise below. Add cells as necessary.\n",
    "\n",
    "1. Use pandas to extract tabular data from the webpage at `http://testing-ground.scraping.pro/table?products=10&years=10&quarters=4`. Display the content of each of the generated DataFrames.  Generally, sites restrict the use of scrapers; [scraping.pro](http://testing-ground.scraping.pro/) provides a set of pages to test web scrapers.  After loading and displaying the data notice that there are issues with the DataFrame including `NaN` values and formatting issues.  We will address some of these issues in later units.\n",
    "\n",
    "2. Use the [MetaWeather API](https://www.metaweather.com/api/) to retrieve weather data for Columbus on January 1, 2018 using the URL `https://www.metaweather.com/api/location/2383660/2018/1/1` with panda's *read_json()* function; here `2383660` is the [WOEID](https://en.wikipedia.org/wiki/WOEID) for Columbus. Use the API documentation to write up a description of the columns in the resulting DataFrame.  To write text in a cell, select *Cell*, *Cell Type*, and *Markdown* from the menus above.  Do not worry about formatting the description text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
