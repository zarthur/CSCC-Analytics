{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3: Exploratory Analysis\n",
    "\n",
    "## Contents\n",
    "\n",
    "* [Contents](#Contents)\n",
    "* [Getting Started](#Getting-Started)\n",
    "* [Selecting Data with Pandas](#Selecting-Data-with-Pandas)\n",
    "* [Exploring a Dataset](#Exploring-a-Dataset)\n",
    "    * [Histograms](#Histograms)\n",
    "    * [Scatter Plots](#Scatter-Plots)\n",
    "    * [Pair Plots: Histograms and Scatter Plots](#Pair-Plots:-Histograms-and-Scatter-Plots)\n",
    "    * [Categorical Data](#Categorical-Data)\n",
    "    * [Plotting Numerical Data with Categorical Data](#Plotting-Numerical-Data-with-Categorical-Data)\n",
    "    * [Box Plots](#Box-Plots)\n",
    "    * [Pivot Tables](#Pivot-Tables)\n",
    "* [Lab Answers](#Lab-Answers)\n",
    "* [Next Steps](#Next-Steps)\n",
    "* [Resources and Further Reading](#Resources-and-Further-Reading)\n",
    "* [Exercises](#Exercises)\n",
    "\n",
    "### Lab Questions\n",
    "\n",
    "[1](#Lab-1), [2](#Lab-2), [3](#Lab-3), [4](#Lab-4), [5](#Lab-5), [6](#Lab-6), [7](#Lab-7), [8](#Lab-8), [9](#Lab-9),  [10](#Lab-10)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "With some data loaded and cleaned, we can begin to look at it more closely and see if we can identify any trends or relationships.  To do this, we can rely on both quantitative methods such as the calculation and analysis of descriptive statistics as well as qualitative methods such as plotting. We'll rely on methods in pandas to calculate descriptive statistics. We'll rely on [Matplotlib](https://matplotlib.org/) and [Seaborn] for plotting(https://seaborn.pydata.org/). Matplotlib is a popular plotting library capable of producing [many different types of plots](https://matplotlib.org/gallery/index.html). Seaborn provides a simpler way of creating many of the plots commonly associated with data analysis and typically produces [nicer looking plots](https://seaborn.pydata.org/examples/index.html).\n",
    "\n",
    "To use Seaborn, we'll make sure it is installed with `pip`.\n",
    "\n",
    "If using [Anaconda](https://www.anaconda.com/download) and the following pip command fails, open the Anaconda prompt on your computer and run the following\n",
    "\n",
    "```\n",
    "conda install --yes seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be creating plots in this notebook.  Before importing any modules, we should indicate to the notebook software how we would like to handle plots.  We can use the [`%matplotlib`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-matplotlib) magic command and `inline` to indicate that we would like plot to appear as static images in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Seaborn installed, we can start importing modules for use in the notebook. Just as we followed convention and imported pandas as `pd`, we will import the Seaborn library as `sns`.  \n",
    "\n",
    "Following the import, we can set the appropriate pandas option to display 100 columns at a time. We can use the Searborn `set()` function to control figure size and the size of marker edges. Setting marker edges allows us to see outliers when working with box plots that would otherwise be invisible due to a bug in Matplotlib and Seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize': (12, 10), \"lines.markeredgewidth\": 0.5 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this unit we'll continue to work with panda's Series and DataFrames to store and manipulate data.  As part of that work, we'll be interested in examining parts of a larger DataFrame.  A common way to select a subset of DataFrame is through the use of masks and filters - this is something we've already done.  For example, consider the following DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.DataFrame(\n",
    "    [\n",
    "        ('John', 'Marketing', '123 Main St', 'Columbus', 'OH', 3),\n",
    "        ('Jane', 'HR', '456 High Ave', 'Columbus', 'OH', 7),\n",
    "        ('Bob',  'HR', '152 Market Rd', 'Cleveland', 'OH', 4),\n",
    "        ('Sue', 'Marketing', '729 Green Blvd', 'Cleveland', 'OH', 8),\n",
    "        ('Tom', 'IT', '314 Oak Dr', 'Cincinnati', 'OH', 11),\n",
    "        ('Kate', 'IT', '841 Elm Ln', 'Cincinnati', 'OH', 2)\n",
    "    ],\n",
    "    columns = (\"name\", \"department\", \"address\", \n",
    "               \"city\", \"state\", \"years_with_company\")\n",
    ")\n",
    "\n",
    "display(employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to work with a specific subset of the data, say only those employees that are in Columbus, we could use the mask `employees.city == 'Columbus'` to filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees[employees.city == 'Columbus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers an alternative [*query()* method](https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-query) for selecting data that allows us to write statements that similar to standard Python syntax. For example, *query()* can be used to select only those employees in Columbus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees.query('city == \"Columbus\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument we provide the *query()* method is a string that indicates the data we'd like extract from the original DataFame.  When comparing string values, we have to to be sure to enclose the inner string in different quotes than the query itself.  \n",
    "\n",
    "Compare the following which both return data for employees that have been with the company for more than 4 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees[employees.years_with_company > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees.query('years_with_company > 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far there doesn't seem to be much of an advantage to one method over the other.  A benefit to using *query()* becomes apparent when our conditions become more complex.  Compare the two methods when we want to find staff that have been with the company for more than 4 years and live in either Cleveland or Columbus.  White space such as line returns and extra indentation has been added for clarity and is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees[(employees.years_with_company > 4) &\n",
    "          ((employees.city == \"Cleveland\") | \n",
    "           (employees.city == \"Columbus\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees.query(\n",
    "    \"years_with_company > 4 and\"\n",
    "    \"(city == 'Cleveland' or \"\n",
    "    \" city == 'Columbus')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument supplied to the *query()* method is more concise and probably easier to read; generally, we write code with readability in mind as it is easier to share or understand later.  \n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-1\"></a><mark> **Lab 1** In the cell below, use the *query()* method to find all employees that live in Columbus and work for HR.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "One potential advantage to the non-*query()* method is programmability.  As we write scripts, we often use variables to store values that will change and use the variables in our selection criteria.  For example, suppose we have a function that routinely allows different departments to find their staff with more than 4 years with the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senior_staff(dept):\n",
    "    # return only those employees in the \n",
    "    # specified department that have been\n",
    "    # with the company for more than 4 years\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the notation we have been using, writing the function body the returns the correct result for a specified department is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senior_staff(dept):\n",
    "    return employees[employees.department == dept]   \n",
    "\n",
    "senior_staff(\"IT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the *query()* method, there are multiple ways we can achieve the same result.  The method suggested by the pandas' documentation makes use of `@`.  We can reference existing variables in the query string in-line by prefixing their names with `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senior_staff(dept):\n",
    "    return employees.query(\"department == @dept\")\n",
    "\n",
    "senior_staff(\"IT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods of selecting data have benefits and disadvantages.  We'll primarily use the method we've been working with but occasionally use *query()*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the EPA/Department of Energy fuel economy dataset set we looked at last time.  Often data cleaning, merging, and exploration are done together - data is cleaned as we examine it for relationships and trends and then the pertinent/interesting data is merged and stored for further analysis.  Though we cleaned and merged the fuel economy and vehicle sales data previously, lets start with the original datasets for this initial exploration.  \n",
    "\n",
    "We can load the data from the `./data/02-vehicles.csv` file using pandas' `read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_data = pd.read_csv(\"./data/02-vehicles.csv\", engine=\"python\")\n",
    "epa_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a summarized data description document for this data, we can display it with the `HTML` function in the `IPython.display` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(filename=\"./data/02-vehicles-description.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of our initial exploration, we'll attempt to catalog/categorize the values in the following columns and see if there are any relationships between pairs of them.\n",
    "\n",
    "- `city08`\n",
    "- `city08U`\n",
    "- `co2`\n",
    "- `c02TailpipeGpm`\n",
    "- `comb08`\n",
    "- `comb08U`\n",
    "- `cylinders`\n",
    "- `displ`\n",
    "- `fuelType1`\n",
    "- `highway08`\n",
    "- `highway08U`\n",
    "- `year`\n",
    "- `VClass`\n",
    "\n",
    "We'll also keep the following fields for each row.  \n",
    "\n",
    "- `make`\n",
    "- `model`\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-2\"></a><mark> **Lab 2** In the cell below, create a copy of the `epa_data` DataFrame containing only the columns listed above.  Store the new DataFrame in a variable named `epa_subset`.  Use the *head()* method to confirm that the new DataFrame contains the correct column data.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "As we've seen before, we can use the DataFrame *describe()* method to quickly calculate some discriptive statistics for each of the numeric columns in the dataframe.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-3\"></a><mark> **Lab 3** In the cell below, use the *describe()* method to calculate descriptive statistics for the numeric columns of `epa_subset`.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Let's look at one column to get an idea of what these values represent. According to the documentation, the `city08` column represnts the fuel economy for city driving with the primary fuel type.  The rows have the following meaning.\n",
    "\n",
    "- `count`: the number of non-null elements in the column; here there are 39,518 non-null values in the `city08` column\n",
    "- `mean`: the sum of all values divided by the number of values; the mean value for `city08` is 18.2 mpg.\n",
    "- `std`: the standard deviation - a measure of the variation of values within a collection, can be thought of as an \"average\" distance to the mean among all the values; the standard deviation of values in the `city08` column is 7.3 mpg.\n",
    "- `min` and `max`: the smallest and largest values, respectively; here we have 6.0 mpg and 150.0 mpg. \n",
    "- `25%`, `50%`, and `75%`: the quartile values that allow us to divide the data into four parts. The first quartile, 25%, corresponds to the value between the minimum and the median; 25% of values are less than this value.  The second quartile is the median, the middle most number among the values; 50% of values are less than the median and 50% of values are greater than the median. The third quartile represents the middle value between the median and the maximum; 25% of values are greater than this value. \n",
    "\n",
    "As we noted previously, *describe()* only display results for numeric columns.  For non-numeric columns, we might be interested in knowing about the data values and how often those values appear.  Below, we iterate through the columns of the DataFrame and if the the column is a string data we display the column name with the output from the *value_counts()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in epa_subset.columns:\n",
    "    if pd.api.types.is_string_dtype(epa_subset[column]):\n",
    "        display(column, epa_subset[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While having access to these results can be useful, we often rely on visualizations to help characterize data or provide insights into potential relationships.  Before generating visualizations, let's address some data quality issues.  First, we can remove duplicates. \n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-4\"></a><mark> **Lab 4** In the cell below, remove duplicate rows from the `epa_subset` DataFrame.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We'll also need to account for missing data - while some methods we'll use to explore the data are able to ignore missing values, other will fail and throw exceptions.\n",
    "\n",
    "From the code below we can see that the `cylinders` and `displ` columns are missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can identify any common properties for rows missing `cylinders` or `displ` data.  We can filter the DataFrame using a mask that corresponds to a row in which any column value is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset[epa_subset.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the rows with missing cylinder and displacement data correspond to electric vehicles.  This makes sense given the fact that electric vehicles do no have an internal combustion engine.  Let's refine the mask to exclude rows where `fuelType` is `Electricity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset[(epa_subset.isna().any(axis=1)) & \n",
    "           (epa_subset.fuelType1 != 'Electricity')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that these rows are anomalies and are simply missing data.\n",
    "\n",
    "Before continuing on, we'll remove rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin getting a higher-level picture of our data, we can use visualizations.  While we have some sense of the distribution of data values from the quartile information calculated by the *describe()* method, a [histograms](https://en.wikipedia.org/wiki/Histogram) can be used to visualize the date distribution.  \n",
    "\n",
    "Both pandas DataFrames and Series have *hist()* methods that can be used to plot histograms. This allows us to create a histogram for a specific column or for each column in a DataFrame with numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.city08.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *hist()* method returns an `AxesSubplot` object that can be used to manipulate the plot - this is what the text above the plot refers to - we can ignore this now.\n",
    "\n",
    "From the plot we can see that most of the values are concentrated between 10 and 30 mpg.  We can also see that the distribution has a positive [skew](https://en.wikipedia.org/wiki/Skewness).  We can confirm this using the column's `skew()` method.  Similarly, we can calculate the [kurtosis](https://en.wikipedia.org/wiki/Kurtosis) using the *kurtosis()* method.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-5\"></a><mark> **Lab 5** Calculate and display the skew and kurtosis of the data in the `city08` column.\n",
    "</mark>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "The pandas *hist()* method relies on Matplotlib and Seaborn to generate the plot. We can generate a histogram directly from Seaborn if we'd like. To do this, we can use the [*distplot()*](https://seaborn.pydata.org/generated/seaborn.distplot.html) function.  By default, the function generates a plot representing the probability distribution of observations rather than the count of values.  To generate a plot based on the count, we have to provide the `kde=False` argument. We can also specify `bins=10` for consistency with the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(epa_subset.city08, kde=False, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the histograms for each of the numeric columns in the DataFrame, we can use the DataFrame's *hist()* method rather than the Series *hist()* method associated with an individual column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the histograms allow us to see the distrubution of data for each column more quickly than looking at results of *describe()* or similar methods.  From a quick glance, we can see that there noticable differences between the values in `city08` and `city08U`. From the data documentation, we know that the `city08` column contains \"unrounded data\" but, when comparing the historgrams between the two columns, it apepars that the \"unrounded\" data contains more zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a histogram is useful to see how data is distributed for a signle column, we often would like to see if any relationships exist between two columns/variables.  We can compare the values of two columns directly using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.plot.scatter(x=\"comb08U\", y=\"comb08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are rows in which `comb08U` has a value of zero but the value of `comb08` is non-zero.  Because it doesn't make sense to round zero to a non-zero value, it's reasonable to conclude that there is missing data for the unrounded values and zero was used as a placeholder. It might be the case that before some point in time only rounded values were stored.  To verify this, we can compare the values of both columns against the `year` data assuming measurements were made around the the time the vehicles were manufactured.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-06\"></a><mark> **Lab 6** In the cells below, verify that rounded values for combined fuel efficiency are available for earlier years compared to to unrounded values by creating two scatter plots. \n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We can see that the `city08U`, `comb08U`, and `highway08U` columns have the same number of zero-valued entries, which supports the idea that unrounded data from earlier years isn't available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"city08U\", \"comb08U\", \"highway08U\"]:\n",
    "    zeros = epa_subset[epa_subset[column] == 0]\n",
    "    display(column, len(zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in mind, we might choose to work with the rounded data if we wanted to work with a larger set of data including more historic data.  If there is a desire to work with unrounded values or we wish to examine only recent data, we could work with the unrounded values.  Having more historic data will be useful to us so we'll work with rounded data.\n",
    "\n",
    "Having a sense of the distribution of a single column's data is important but we're often interested in how one or more columns influence another column. When working with two columns, we often use scatter plots to asses potential relationships.  We can create a scatter plot for two columns as we did above when looking at rounded and unrounded data compared to years.  As another example, let's compare the values of `comb08`, the combined highway and city fuel efficiency in miles/gallon, and `co2`, the tailpipe CO2 emissions in grams/mile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.plot.scatter(x=\"comb08\", y=\"co2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there appears to be a relationship between fuel efficiency and carbon dioxide emissions - as fuel efficiency improves, emissions decrease.  We'll examine this relationship further in a later unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair Plots: Histograms and Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as it was helpful to be able to quickly visualize distribution data for each of the numeric columns in our dataset, we can use a [*pairplot*](https://seaborn.pydata.org/generated/seaborn.pairplot.html) to visualize the pairwise relationships between columns.  In the example below, we first further reduce the columns we'll examine then use the Seaborn *pairplot()* function to generate the pairwise scatter plots for those columns.  Note that when a column is paired with itself, the column's histogram is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ \"co2\", \"comb08\", \"cylinders\", \"displ\"]\n",
    "sns.pairplot(epa_subset[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is a form of symmetry to the plots with respect to the plots to the left and below the histograms and the plots to the right and above.  For example, the the second plot in the first row and the first plot in the second column both show the relationship between `co2` and `comb08` - the axis to which each variable corresponds differs but the relationship is the same.\n",
    "\n",
    "Using pair plots can help us quickly identify which columns or variables are dependent on other columns/variables.  \n",
    "\n",
    "The `co2`column contains quite a few values that appear to be zero but are -1 (as can be seen from the output of *describe()*.  Let's see what those are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.query(\"co2 == -1\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its not immediately clear what might be the reason for the carbon dioxide emissions having a value of -1 but we'll remove them for the remainder of our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset = epa_subset.query('co2 >= 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, let's look at the pair plots again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ \"co2\", \"comb08\", \"cylinders\", \"displ\"]\n",
    "sns.pairplot(epa_subset[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the examples above provide insight into numeric data, they don't tell us about columns that contain categorical data such as `VClass`. \n",
    "\n",
    "A typical method of visualizing categorical data is with a bar plot.  Both pandas and Seaborn provide methods of generating bar plots.\n",
    "\n",
    "For a given column in the DataFrame, the *value_counts()* method returns a Series.  Series, as we've seen before, have a *plot()* method.  We can explicitly create a bar chart using the `kind=bar` or `kind=barh` arguments to the *plot()* method for a vertical or horizontal bar chart, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.VClass.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the categories is determined by the Series used to create the chart; because the results of *value_counts()* are ordered, the bars in the resulting plot are ordered.  \n",
    "\n",
    "We can create a similar plot using the Seaborn [*countplot()*](https://seaborn.pydata.org/generated/seaborn.countplot.html) function. To create a vertical bar chart, we can use the `x` keyword argument to specify source data; to create a horizontal bar chart, we can use the `y` keyword argument to specify the source data.  Below, we create a horizontal bar chart for the vehicle class data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=epa_subset.VClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the data isn't ordered in the same way it was before; by default, categories are ordered based on when they appear in the source data.  To impose a different ordering, we can use the `order` keyword argument with the *countplot()* function.\n",
    "\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-7\"></a><mark> **Lab 7** In the cell below, use the Seaborn *countplot()* function to generate a bar chart visualizing the counts for each of the vehicle classes in the `VClass` column.  Use the `order` keyword argument to order the categories based on the number of entries for each class.  Use the index from the series returned by the `value_counts()` method for ordering information. \n",
    "</mark>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "As you look at these bar charts, you might notice that there are several vehicle class names that are similar to other classes, for example, \"Special Purpose Vehicles\" and \"Special Purpose Vehicle\". Listing the distinct vehicles alphabetically helps to see this better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(epa_subset.VClass.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean this data a bit by replacing similar values with one value. In addition to combining categories with similar names, we'll combine two- and four-wheel drive vehicles into the category without an indication of drive and the different types of vans into the general van category. \n",
    "\n",
    "There are a variety of way of doing this.  A for-loop would work but, as mentioned previously, for-loops should be avoided.  An alternate way of replacing a column's values is through the use of the *apply()* method that we've used before.  We could use the [*map()*] method and supply a dictionary where the keys are correspond to current values in the column and the associated values represent the replacement data, but we have to provide a mapping for every column - even those we don't need to alter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclass_map = {\n",
    "    'Minivan - 2WD': 'Minivan',\n",
    "    'Minivan - 4WD': 'Minivan',\n",
    "    'Small Pickup Trucks 2WD': 'Small Pickup Trucks',\n",
    "    'Small Pickup Trucks 4WD': 'Small Pickup Trucks',\n",
    "    'Small Sport Utility Vehicle 2WD': 'Small Sport Utility Vehicle',\n",
    "    'Small Sport Utility Vehicle 4WD': 'Small Sport Utility Vehicle',\n",
    "    'Special Purpose Vehicle': 'Special Purpose Vehicles',\n",
    "    'Special Purpose Vehicle 2WD': 'Special Purpose Vehicles',\n",
    "    'Special Purpose Vehicle 4WD': 'Special Purpose Vehicles',\n",
    "    'Special Purpose Vehicles/2wd': 'Special Purpose Vehicles',\n",
    "    'Special Purpose Vehicles/4wd': 'Special Purpose Vehicles',\n",
    "    'Sport Utility Vehicle - 2WD': 'Sport Utility Vehicle',\n",
    "    'Sport Utility Vehicle - 4WD': 'Sport Utility Vehicle',\n",
    "    'Standard Pickup Trucks 2WD': 'Standard Pickup Trucks', \n",
    "    'Standard Pickup Trucks 4WD': 'Standard Pickup Trucks',\n",
    "    'Standard Pickup Trucks/2wd': 'Standard Pickup Trucks',\n",
    "    'Standard Sport Utility Vehicle 2WD': 'Standard Sport Utility Vehicle',\n",
    "    'Standard Sport Utility Vehicle 4WD': 'Standard Sport Utility Vehicle',\n",
    "    'Vans Passenger': 'Vans',\n",
    "    'Vans, Cargo Type': 'Vans',\n",
    "    'Vans, Passenger Type': 'Vans'\n",
    "}\n",
    "    \n",
    "def replace(value):\n",
    "    if value in vclass_map:\n",
    "        return vclass_map[value]\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "epa_subset.VClass = epa_subset.VClass.apply(replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the similar values replaced, let's look at the value count bar chart again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=epa_subset.VClass, \n",
    "              order=epa_subset.VClass.value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative to how often a given vehicle class appears in the data, we might be interested in knowing the mean fuel economy for each class.  In order to this, we can use panda's [*group by* functionality](https://pandas.pydata.org/pandas-docs/stable/groupby.html) that allows us to creates groups of data within the dataset and calculate an aggregate value for each group; this is similar to the standard SQL [*group by*](https://www.w3schools.com/sql/sql_groupby.asp) statement.  \n",
    "\n",
    "To create a grouping, we can use the DataFrame's [*groupby()*](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) method specifying at least one column whose values should be used for grouping. The code below groups the data in `epa_subset` by values in the `VClass` column then computes the mean across the other columns for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.groupby(['VClass']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we'd like the aggregated values for a single column, we can specify that column after the call to the the *groupby()* method or after the call to the aggregation function. It's generally better to reduce the size of the dataset over which a calculation is applied so we should select the column of interest before doing the aggregation calculation. We can select the `comb08` column after grouping the data and then calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mpg_by_vclass = epa_subset.groupby(['VClass'])['comb08'].mean()\n",
    "display(mean_mpg_by_vclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this aggregated data, stored in a pandas Series, to create a bar chart.  Because we are no longer interested in the number of times a `VClass` value appears, we cannot use the Seaborn *countplot()* function.  Instead, we can use [*barplot()*].  Before plotting, we sort the Series using the *sort_values()* method to indicate that we'd like to sort the Series by its values; we specify `inplace=True` to alter the existing Series object and `ascending=False` to sort the values in descending order.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mpg_by_vclass.sort_values(inplace=True, ascending=False)\n",
    "sns.barplot(x=mean_mpg_by_vclass.values, y=mean_mpg_by_vclass.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have used the *plot()* method on the Series itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mpg_by_vclass.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Numerical Data with Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vehicle classes sorted by combined city and highway fuel economy, let's see how some the relationships we looked at in the pair plot above differ based on classes.  Let's select three vehicle classes, the one with the greatest mean fuel economy, the one with the least mean fuel economy, and the class corresponding to median of the aggregated values. We can use the *min()*, *max()*, and *median()* methods to find the corresponding values within the Series and use a filter with those values to get the index values (the vehicle class names).  The following identifies the vehicle class with the median value for mean combined fuel economy. Note that the filter returns a collection of rows that match the given criteria; to get the first and only result, we use bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mpg_by_vclass[mean_mpg_by_vclass == mean_mpg_by_vclass.median()].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect the three classes we're interested in into one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclass_sample = [\n",
    "    mean_mpg_by_vclass[mean_mpg_by_vclass == mean_mpg_by_vclass.min()].index[0],\n",
    "    mean_mpg_by_vclass[mean_mpg_by_vclass == mean_mpg_by_vclass.median()].index[0],\n",
    "    mean_mpg_by_vclass[mean_mpg_by_vclass == mean_mpg_by_vclass.max()].index[0]\n",
    "]\n",
    "\n",
    "vclass_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this list to reduce the size of our `epa_subset` DataFrame.  The mask we'll use to filter the data will rely on the [*isin()*](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isin.html) method that tests whether a value is in a specified list or not; this is similar to the Python *in* keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_vclass_sample = epa_subset[epa_subset.VClass.isin(vclass_sample)]\n",
    "epa_vclass_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could achieve the same result using *query()* and a more Python-like syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_vclass_sample = epa_subset.query('VClass in @vclass_sample')\n",
    "epa_vclass_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these three vehicle classes, let's look at the pair plot from earlier.  We can use the values in the `VClass` column to determine the coloring of markers in the various plots.  To to this, we specify the column name with the `hue` argument when we call *pairplot()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ \"co2\", \"comb08\", \"cylinders\", \"displ\", \"VClass\"]\n",
    "sns.pairplot(epa_vclass_sample[columns], hue=\"VClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data with how we chose values for `VClass` in mind, we can begin to see some trends.  For example, the more fuel-efficient vehicles, like small station wagons, have engines with a smaller displacement and emit less carbon dioxide. Similarly, vans, which represent the least fuel-efficient vehicles, have engines with a greater displacement and emit more carbon dioxide.\n",
    "\n",
    "We can look at pairwise relationships one at a time if we would like. Let's look at the scatter plot of `comb08` and `co2`.  While we could use the *scatter()* method we used earlier, it would take some work to add the marker coloring based on `VClass` that we have in the pair plot above.  Instead, we'll use the Seaborn [*lmplot()*](https://seaborn.pydata.org/generated/seaborn.lmplot.html) function.  By default, this plot type will also show the linear regression that fits the data.  We'll disable this feature for now but will use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='comb08', y=\"co2\", hue='VClass', \n",
    "           data=epa_vclass_sample, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there appears to be an indirect relationship between the two variables: as fuel economy increases, carbon dioxide emissions decrease.\n",
    "\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-8\"></a><mark> **Lab 8** In the cell below, create a similar scatter plot for `displ` and `co2` with marker coloring determined by vehicle class.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at modeling these relationships in the next unit, but for now, let's return to the larger subset of data with all the vehicle classes.  So far, we've used the *describe()* method, histograms, and bar charts to get a sense of the distribution and other properties of some of the numeric data in our dataset.  Another common way to explore numeric data is through the use of [box plots](https://en.wikipedia.org/wiki/Box_plot).\n",
    "\n",
    "To understand the components of a box plot, consider the following example Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.Series([-4, -1, -0.5, 0, 0.5, 1, 4], name=\"Example\")\n",
    "example.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a the box plot for the same Series and compare it to the output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red line in the box corresponds to the median or 50th percentile value.  The lines above and below the median correspond to the 75th and 25th percentile values, respectively.  The narrower lines above and below these lines correspond to the maximum and minimum values excluding outliers.  Outliers are symbolized by the small circular markers. Outliers represent values that can be considered \"distant\" from other values.  There are various ways of defining what constitutes an outlier but a common method relies on interquartile range, *IQR*, the difference between the third and first quartile, or in terms of percentiles, the difference between the 75th and 25th percentiles.  Using interquartile range a value can be considered an outlier if it satisfies one of the following:\n",
    "\n",
    "- it is greater than the sum of the 75th percentile and 1.5 times the interquartile range \n",
    "- it is less than the difference of 25th percentile and 1.5 times the interquartile range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.co2.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the median is about 400 g/mile and that there are quite a few outliers.  \n",
    "\n",
    "Next, let's look at the `comb08` and `cylinders` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.comb08.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.cylinders.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot for `cylinders` is a bit unusual.  We see that the median and the 75th percentile values are the same.  This is due to the fact that there are few different values and the distribution of those values as shown by *describe()* and *value_counts()* below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(epa_subset.cylinders.describe())\n",
    "display(epa_subset.cylinders.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a name=\"Lab-9\"></a><mark> **Lab 9** In the cell below, create a box plot for the `displ` column of the `epa_subset` DataFrame.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Let's look at the box plot for the `displ` column again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.displ.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate thresholds for the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = epa_subset.displ.quantile(0.25)  # first quartile\n",
    "q3 = epa_subset.displ.quantile(0.75)  # third quartile\n",
    "IQR = q3 - q1  # IQR\n",
    "lower_threshold = q1 - 1.5 * IQR  # lower threshold\n",
    "upper_threshold = q3 + 1.5 * IQR  # upper threshold\n",
    "display(lower_threshold, upper_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these calculations, an outlier for engine displacement is anything greater than 6.5 or less than about -0.7; for this data there are no lower outliers as negative displacement is meaningless.\n",
    "\n",
    "<hr>\n",
    "<a name=\"Lab-10\"></a><mark> **Lab 10** In the cell below, calculate the lower and upper thresholds for outliers for the `co2` column in the `epa_subset` DataFrame.\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn also includes functionality to create box plots using the [*boxplot()*](https://seaborn.pydata.org/generated/seaborn.boxplot.html) function but the pandas DataFrame *plot()* method tends to produce easier-to-read plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=epa_subset.co2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's *boxplot()* function does work well when we want to show the box plots from one column separated by categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"co2\", y=\"VClass\", data=epa_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides the ability to create [pivot tables](https://en.wikipedia.org/wiki/Pivot_table) to aggregate and summarize data.  To crate a pivot table, we can use the DataFrame's [*pivot_table()*](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot_table.html) method and, at a minimum, specifying which column should be used as the index of the new table; the index serves as the column by which values are grouped and aggregated.  By default, the mean is used as the aggregation function but we can specify any appropriate function using the `aggfunc` keyword argument.\n",
    "\n",
    "Let's create a pivot table that groups the data by `year` and aggregates data by calculating the median of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.pivot_table(index=\"year\", aggfunc=pd.np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose a subset of columns by listing them using the `values` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.pivot_table(index=\"year\", \n",
    "                       values=[\"city08\", \"comb08\", \"highway08\"], \n",
    "                       aggfunc=pd.np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fan also further divide the data by specifying additional indexes or through the `columns` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.pivot_table(index=[\"year\", \"fuelType1\"],\n",
    "                       values=[\"city08\", \"comb08\", \"highway08\"], \n",
    "                       aggfunc=pd.np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_subset.pivot_table(index=\"year\", \n",
    "                       columns=\"fuelType1\",\n",
    "                       values=[\"city08\", \"comb08\", \"highway08\"], \n",
    "                       aggfunc=pd.np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We an also use pivot tables as inputs for visualizations.  Let's compare city and highway fuel economy for the various vehicle classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = (\n",
    "    epa_subset.pivot_table(\n",
    "        index=[\"VClass\"],\n",
    "        values=[\"city08\", \"highway08\"],\n",
    "        aggfunc=pd.np.median)\n",
    "    .sort_values(by=\"highway08\"))\n",
    "display(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can create a [heatmap](https://en.wikipedia.org/wiki/Heat_map) using Seaborn's [*heatmap()*](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function.  In addition to specifying the pivot table as the data source, we can show the values for each rectangle using the `annot` keyword argument and specify the colormap using the `cmap` keyword argument with a [matplotlib colormap  name](https://matplotlib.org/users/colormaps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pivot, annot=True, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ```python\n",
    "   employees.query(\n",
    "       \"city == 'Columbus' and \"\n",
    "       \"department == 'HR'\"\n",
    "   )\n",
    "   ```\n",
    "   \n",
    "2. ```python\n",
    "   columns = [\"city08\", \"city08U\", \"co2\", \"co2TailpipeGpm\", \"comb08\", \"comb08U\", \n",
    "              \"cylinders\", \"displ\", \"fuelType1\", \"highway08\", \"highway08U\", \n",
    "              \"make\", \"model\", \"VClass\", \"year\"]\n",
    "   epa_subset = epa_data[columns].copy()\n",
    "   epa_subset.head()\n",
    "   ```\n",
    "   \n",
    "3. ```python\n",
    "   epa_subset.describe()\n",
    "   ```\n",
    "   \n",
    "4. ```python\n",
    "   epa_subset.drop_duplicates(inplace=True)\n",
    "   ```\n",
    "   \n",
    "5. ```python\n",
    "   display(epa_subset.city08.skew())\n",
    "   display(epa_subset.city08.kurtosis())\n",
    "   ```\n",
    "   \n",
    "6. ```python\n",
    "   epa_subset.plot.scatter(x=\"year\", y=\"comb08\")\n",
    "   ```\n",
    "   \n",
    "   and\n",
    "   \n",
    "   ```python\n",
    "   epa_subset.plot.scatter(x=\"year\", y=\"comb08U\")\n",
    "   ```\n",
    "   \n",
    "7. ```python\n",
    "   sns.countplot(y=epa_subset.VClass, order=epa_subset.VClass.value_counts().index)\n",
    "   ```\n",
    "   \n",
    "8. ```python\n",
    "   sns.lmplot(x=\"displ\", y=\"co2\", hue='VClass', data=epa_vclass_sample, fit_reg=False)\n",
    "   ```\n",
    "   \n",
    "9. ```python\n",
    "   epa_subset.displ.plot(kind='box')\n",
    "   ```\n",
    "   \n",
    "10. ```python\n",
    "    q1 = epa_subset.co2.quantile(0.25)\n",
    "    q3 = epa_subset.co2.quantile(0.75)\n",
    "    IQR = q3 - q1\n",
    "    lower_threshold = q1 - 1.5 * IQR\n",
    "    upper_threshold = q3 + 1.5 * IQR\n",
    "    display(lower_threshold, upper_threshold)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "We've identified some potential relationships among columns within the fuel economy dataset.  In the next unit we'll create mathematical models for some of these relationships and see how well the model fits the existing data.\n",
    "\n",
    "We'll continue to use plots and charts to understand the data but mostly for exploratory purposes.  Visualizations also serve as great tools for conveying information; we'll explore explanatory visualizations later.\n",
    "\n",
    "## Resources and Further Reading\n",
    "\n",
    "- [An Introduction to Seaborn](https://seaborn.pydata.org/introduction.html)\n",
    "- [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)\n",
    "- [*Practical Statistics for Data Scientists* by Bruce and Bruce, Chapter 1: Exploratory Data Analysis (Safari Books)](http://proquest.safaribooksonline.com.cscc.ohionet.org/book/databases/9781491952955/1dot-exploratory-data-analysis/eda_html?uicode=ohlink)\n",
    "- [*Python: Data Analytics and Visualization* by Phuong, et. al., Data Exploration (Safari Books)](http://proquest.safaribooksonline.com.cscc.ohionet.org/book/programming/python/9781788290098/implementing-logistic-regression-with-python/ch06lvl2sec00083_html?uicode=ohlink)\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. We created a set of box plots for the values in the `co2` column separated by `VClass` from the `epa_data` DataFrame using `sns.boxplot(x=\"co2\", y=\"VClass\", data=epa_subset)`.  Prior to that, when working with bar charts, we specified an ordering for the categorical data using the `order` keyword argument.  Modify the box plot so categories are ordered by median carbon dioxide emissions from least to greatest.  See the image below for the desired plot.\n",
    "\n",
    "2. Load county auditor data, either one county's data from one of the data sources we've used or from the combined data we saved to a database, and create a pair plot that compares sales price, area, number of bedrooms, and bathrooms.  Are there any potential relationships between any of these variables?\n",
    "\n",
    "<figure>\n",
    "<img src=\"./images/03-boxplots.png\" alt=\"box plots for co2 emission by median\">\n",
    "<figcaption style=\"text-align: center; font-weight: bold\">Exercise 1 - Box plots for carbon dioxide emission by vehicle class sorted by median emission</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
